{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Contextual Assistant (Chatbot)\n",
    "- In this project, a chatbot is developed to make a conversation with users about movies and help/support them to gain information on movies and choose a movie to watch.\n",
    "- In order to develop the chatbot, the \"IMDB's movies\" dataset is deployed which is consisted of 28 features of 5043 movies. In this project, some columns(features) of dataset such as movie-title, director_name, genres , imdb_score, title_year, color and gross and budget are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller   \n",
       "3                 27000.0  448130642.0                  Action|Thriller   \n",
       "4                   131.0          NaN                      Documentary   \n",
       "\n",
       "          ...          num_user_for_reviews language  country  content_rating  \\\n",
       "0         ...                        3054.0  English      USA           PG-13   \n",
       "1         ...                        1238.0  English      USA           PG-13   \n",
       "2         ...                         994.0  English       UK           PG-13   \n",
       "3         ...                        2701.0  English      USA           PG-13   \n",
       "4         ...                           NaN      NaN      NaN             NaN   \n",
       "\n",
       "        budget  title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
       "0  237000000.0      2009.0                  936.0        7.9          1.78   \n",
       "1  300000000.0      2007.0                 5000.0        7.1          2.35   \n",
       "2  245000000.0      2015.0                  393.0        6.8          2.35   \n",
       "3  250000000.0      2012.0                23000.0        8.5          2.35   \n",
       "4          NaN         NaN                   12.0        7.1           NaN   \n",
       "\n",
       "  movie_facebook_likes  \n",
       "0                33000  \n",
       "1                    0  \n",
       "2                85000  \n",
       "3               164000  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"movie_metadata.csv\", encoding=\"utf-8\") #Read data\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n",
       "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
       "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
       "       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n",
       "       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n",
       "       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n",
       "       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n",
       "       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RASA A.I. Toolkit\n",
    "\n",
    "In order to develop a chatbot, the RASA Stack AI toolkit is deployed which is consisted of two main components. The components are as follows:\n",
    "- **RASA NLU (Natural Language Understanding)** which is used to classify the intent of user and extract the entity.\n",
    "- **RASA core** The dialogue management is done by RASA core. Moreover, RASA core take the structured output of RASA NLU and predicts the best next action using predictive models such as LSTM. \n",
    "  \n",
    "Note that dialogue management is deployed to keep the track of conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RASA NLU\n",
    "\n",
    "RASA NLU component is developed by taking the following steps:\n",
    "\n",
    "1. As a first step, data is collected. In this section, the data that is used to train the classifier are \"Intent\" and \"Entity\" which is saved in \"intents.md\" file.\n",
    "2. The next step is to define a pipeline to process and classify the user's intent.\n",
    "   RASA NLU has pre_designed pipelines for deffrent languages and purposes. In this project, The \"spacy_sklearn\" pipeline is deployed.(Spacy module is advanced NLP library and scikit-learn module is used for classification purposes)\n",
    "   The chosen pipeline is in \"config.yml\" file.\n",
    "3. As the last step, the RASA NLU model is trained using the train data and defined pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in c:\\anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages (2.0.0)\n",
      "\n",
      "    Linking successful\n",
      "    C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages\\en_core_web_sm\n",
      "    -->\n",
      "    C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages\\spacy\\data\\en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m spacy download en\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of intents.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 157 (9 distinct intents)\n",
      "\t- Found intents: 'deny', 'movie_suggestion', 'goodbye', 'inform', 'affirm', 'content_check', 'thanks', 'greet', 'General_info'\n",
      "\t- entity examples: 104 (5 distinct entities)\n",
      "\t- found entities: 'imdb', 'themecolor', 'movie', 'genre', 'year'\n",
      "\n",
      "INFO:rasa_nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component nlp_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_entity_featurizer_regex\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_crf\n",
      "WARNING:rasa_nlu.extractors.crf_entity_extractor:Misaligned entity annotation in sentence 'I am intrested in Weekend.Can you help me?'. Make sure the start and end values of the annotated training examples end at token boundaries (e.g. don't include trailing whitespaces or punctuation).\n",
      "WARNING:rasa_nlu.extractors.crf_entity_extractor:Misaligned entity annotation in sentence 'Introduce some fantacy movies that are produced after1990.'. Make sure the start and end values of the annotated training examples end at token boundaries (e.g. don't include trailing whitespaces or punctuation).\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_synonyms\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_sklearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.4s finished\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'C:\\mie1513\\assignment-cai-sfalaki\\assignment\\models\\nlu\\default\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"intents.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data, verbose=True)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RASA Core\n",
    "\n",
    "The dialogue management is performed by RASA Core component. To train the RASA Core component the following steps are taken:  \n",
    "\n",
    "1. DATA collection. The needed data for this part are stories and actions.\n",
    "\n",
    "   Stories are example converstations. RASA Core using this data would learn how to predict the best next action. The collected data is saved on \"stories.md\" file.\n",
    "   \n",
    "   Actions is consisted of actions taht are taken by chatbot to satisfy user's needs.\n",
    "2. Model training. The model is trained using the collected data to predict the next best action.\n",
    "   Note that there is no need of importing TensorFlow mmodeules and train a moel. The RASA Core takes care of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:apscheduler.scheduler:Scheduler started\n",
      "C:\\Anaconda\\envs\\mie451-assignment-ci\\lib\\site-packages\\pykwalify\\core.py:99: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  data = yaml.load(stream)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 9/9 [00:00<00:00, 163.63it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|██████████████████████████████████████████████| 9/9 [00:00<00:00, 54.88it/s, # trackers=9]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 9/9 [00:00<00:00, 53.89it/s, # trackers=17]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 9/9 [00:00<00:00, 46.15it/s, # trackers=18]\n",
      "Processed actions: 806it [00:04, 199.21it/s, # examples=806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 35)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8704      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 9,232\n",
      "Trainable params: 9,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Fitting model with 806 total samples and a validation split of 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "806/806 [==============================] - ETA: 20s - loss: 2.7977 - acc: 0.03 - ETA: 3s - loss: 2.7205 - acc: 0.1187 - ETA: 2s - loss: 2.6820 - acc: 0.203 - ETA: 1s - loss: 2.6374 - acc: 0.260 - ETA: 0s - loss: 2.6131 - acc: 0.279 - ETA: 0s - loss: 2.6057 - acc: 0.287 - ETA: 0s - loss: 2.5806 - acc: 0.303 - ETA: 0s - loss: 2.5642 - acc: 0.308 - ETA: 0s - loss: 2.5569 - acc: 0.307 - 1s 2ms/step - loss: 2.5561 - acc: 0.3077\n",
      "Epoch 2/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.5137 - acc: 0.250 - ETA: 0s - loss: 2.4328 - acc: 0.304 - ETA: 0s - loss: 2.3958 - acc: 0.324 - ETA: 0s - loss: 2.3221 - acc: 0.365 - ETA: 0s - loss: 2.3021 - acc: 0.367 - ETA: 0s - loss: 2.3018 - acc: 0.371 - ETA: 0s - loss: 2.2749 - acc: 0.379 - 0s 529us/step - loss: 2.2752 - acc: 0.3710\n",
      "Epoch 3/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.4162 - acc: 0.250 - ETA: 0s - loss: 2.2335 - acc: 0.302 - ETA: 0s - loss: 2.2138 - acc: 0.322 - ETA: 0s - loss: 2.1753 - acc: 0.350 - ETA: 0s - loss: 2.1742 - acc: 0.353 - ETA: 0s - loss: 2.1653 - acc: 0.357 - ETA: 0s - loss: 2.1575 - acc: 0.362 - ETA: 0s - loss: 2.1451 - acc: 0.371 - ETA: 0s - loss: 2.1092 - acc: 0.384 - 1s 682us/step - loss: 2.1258 - acc: 0.3722\n",
      "Epoch 4/200\n",
      "806/806 [==============================] - ETA: 1s - loss: 2.4290 - acc: 0.218 - ETA: 0s - loss: 2.2018 - acc: 0.312 - ETA: 0s - loss: 2.0870 - acc: 0.350 - ETA: 0s - loss: 2.0528 - acc: 0.365 - ETA: 0s - loss: 2.0662 - acc: 0.358 - ETA: 0s - loss: 2.0769 - acc: 0.351 - ETA: 0s - loss: 2.0668 - acc: 0.353 - ETA: 0s - loss: 2.0522 - acc: 0.360 - ETA: 0s - loss: 2.0373 - acc: 0.365 - 1s 677us/step - loss: 2.0275 - acc: 0.3722\n",
      "Epoch 5/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.1015 - acc: 0.312 - ETA: 0s - loss: 1.8594 - acc: 0.418 - ETA: 0s - loss: 1.9467 - acc: 0.378 - ETA: 0s - loss: 1.9588 - acc: 0.358 - ETA: 0s - loss: 1.9500 - acc: 0.370 - ETA: 0s - loss: 1.9584 - acc: 0.364 - ETA: 0s - loss: 1.9474 - acc: 0.376 - ETA: 0s - loss: 1.9423 - acc: 0.377 - ETA: 0s - loss: 1.9529 - acc: 0.372 - 0s 609us/step - loss: 1.9558 - acc: 0.3710\n",
      "Epoch 6/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.1249 - acc: 0.250 - ETA: 0s - loss: 2.0228 - acc: 0.328 - ETA: 0s - loss: 1.9174 - acc: 0.375 - ETA: 0s - loss: 1.8888 - acc: 0.380 - ETA: 0s - loss: 1.8783 - acc: 0.383 - ETA: 0s - loss: 1.8330 - acc: 0.401 - ETA: 0s - loss: 1.8512 - acc: 0.389 - ETA: 0s - loss: 1.8800 - acc: 0.375 - 0s 567us/step - loss: 1.8861 - acc: 0.3722\n",
      "Epoch 7/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.8455 - acc: 0.375 - ETA: 0s - loss: 1.6882 - acc: 0.453 - ETA: 0s - loss: 1.7889 - acc: 0.400 - ETA: 0s - loss: 1.7825 - acc: 0.396 - ETA: 0s - loss: 1.7931 - acc: 0.391 - ETA: 0s - loss: 1.7917 - acc: 0.387 - ETA: 0s - loss: 1.7957 - acc: 0.388 - ETA: 0s - loss: 1.7945 - acc: 0.388 - 0s 582us/step - loss: 1.8000 - acc: 0.3871\n",
      "Epoch 8/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.5052 - acc: 0.468 - ETA: 0s - loss: 1.6209 - acc: 0.437 - ETA: 0s - loss: 1.6819 - acc: 0.442 - ETA: 0s - loss: 1.6878 - acc: 0.446 - ETA: 0s - loss: 1.7279 - acc: 0.420 - ETA: 0s - loss: 1.7290 - acc: 0.409 - ETA: 0s - loss: 1.7012 - acc: 0.417 - 0s 440us/step - loss: 1.7009 - acc: 0.4169\n",
      "Epoch 9/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.6855 - acc: 0.375 - ETA: 0s - loss: 1.7406 - acc: 0.380 - ETA: 0s - loss: 1.7137 - acc: 0.390 - ETA: 0s - loss: 1.6999 - acc: 0.395 - ETA: 0s - loss: 1.6597 - acc: 0.416 - ETA: 0s - loss: 1.6333 - acc: 0.425 - 0s 447us/step - loss: 1.6037 - acc: 0.4330\n",
      "Epoch 10/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.5297 - acc: 0.500 - ETA: 0s - loss: 1.5323 - acc: 0.427 - ETA: 0s - loss: 1.5426 - acc: 0.440 - ETA: 0s - loss: 1.5300 - acc: 0.449 - ETA: 0s - loss: 1.5043 - acc: 0.468 - 0s 335us/step - loss: 1.4946 - acc: 0.4739\n",
      "Epoch 11/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.4289 - acc: 0.593 - ETA: 0s - loss: 1.3444 - acc: 0.553 - ETA: 0s - loss: 1.3821 - acc: 0.531 - ETA: 0s - loss: 1.3480 - acc: 0.555 - ETA: 0s - loss: 1.3695 - acc: 0.552 - 0s 345us/step - loss: 1.3786 - acc: 0.5509\n",
      "Epoch 12/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.2965 - acc: 0.562 - ETA: 0s - loss: 1.2673 - acc: 0.593 - ETA: 0s - loss: 1.2949 - acc: 0.602 - ETA: 0s - loss: 1.2890 - acc: 0.609 - ETA: 0s - loss: 1.2863 - acc: 0.613 - 0s 330us/step - loss: 1.2563 - acc: 0.6266\n",
      "Epoch 13/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.2901 - acc: 0.656 - ETA: 1s - loss: 1.1719 - acc: 0.703 - ETA: 0s - loss: 1.1719 - acc: 0.697 - ETA: 0s - loss: 1.2018 - acc: 0.664 - ETA: 0s - loss: 1.1824 - acc: 0.665 - ETA: 0s - loss: 1.1787 - acc: 0.664 - 0s 434us/step - loss: 1.1648 - acc: 0.6762\n",
      "Epoch 14/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 1.0453 - acc: 0.750 - ETA: 0s - loss: 1.0867 - acc: 0.745 - ETA: 0s - loss: 1.0206 - acc: 0.763 - ETA: 0s - loss: 1.0733 - acc: 0.731 - ETA: 0s - loss: 1.0789 - acc: 0.735 - 0s 325us/step - loss: 1.0676 - acc: 0.7382\n",
      "Epoch 15/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.9004 - acc: 0.781 - ETA: 0s - loss: 0.9521 - acc: 0.803 - ETA: 0s - loss: 0.9597 - acc: 0.802 - ETA: 0s - loss: 0.9762 - acc: 0.783 - ETA: 0s - loss: 0.9810 - acc: 0.779 - 0s 337us/step - loss: 0.9720 - acc: 0.7829\n",
      "Epoch 16/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.9305 - acc: 0.781 - ETA: 0s - loss: 0.9426 - acc: 0.796 - ETA: 0s - loss: 0.9469 - acc: 0.798 - ETA: 0s - loss: 0.9304 - acc: 0.802 - ETA: 0s - loss: 0.9150 - acc: 0.814 - ETA: 0s - loss: 0.8973 - acc: 0.819 - 0s 442us/step - loss: 0.8955 - acc: 0.8226\n",
      "Epoch 17/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.7092 - acc: 0.843 - ETA: 0s - loss: 0.8256 - acc: 0.852 - ETA: 0s - loss: 0.8122 - acc: 0.872 - ETA: 0s - loss: 0.8204 - acc: 0.862 - ETA: 0s - loss: 0.8167 - acc: 0.860 - ETA: 0s - loss: 0.8121 - acc: 0.858 - 0s 378us/step - loss: 0.8137 - acc: 0.8561\n",
      "Epoch 18/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.8782 - acc: 0.906 - ETA: 0s - loss: 0.8357 - acc: 0.859 - ETA: 0s - loss: 0.8153 - acc: 0.859 - ETA: 0s - loss: 0.7818 - acc: 0.864 - ETA: 0s - loss: 0.7730 - acc: 0.864 - ETA: 0s - loss: 0.7619 - acc: 0.872 - 0s 402us/step - loss: 0.7481 - acc: 0.8772\n",
      "Epoch 19/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.6569 - acc: 0.906 - ETA: 0s - loss: 0.6691 - acc: 0.895 - ETA: 0s - loss: 0.7073 - acc: 0.893 - ETA: 0s - loss: 0.6954 - acc: 0.897 - ETA: 0s - loss: 0.6920 - acc: 0.898 - ETA: 0s - loss: 0.6849 - acc: 0.895 - ETA: 0s - loss: 0.6748 - acc: 0.902 - 0s 525us/step - loss: 0.6746 - acc: 0.9020\n",
      "Epoch 20/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.5722 - acc: 0.937 - ETA: 0s - loss: 0.6793 - acc: 0.914 - ETA: 0s - loss: 0.6428 - acc: 0.919 - ETA: 0s - loss: 0.6097 - acc: 0.911 - ETA: 0s - loss: 0.5990 - acc: 0.917 - ETA: 0s - loss: 0.5966 - acc: 0.916 - ETA: 0s - loss: 0.6022 - acc: 0.911 - ETA: 0s - loss: 0.6140 - acc: 0.903 - ETA: 0s - loss: 0.6152 - acc: 0.904 - ETA: 0s - loss: 0.6130 - acc: 0.902 - 1s 710us/step - loss: 0.6162 - acc: 0.9020\n",
      "Epoch 21/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.6347 - acc: 0.875 - ETA: 0s - loss: 0.5720 - acc: 0.901 - ETA: 0s - loss: 0.5544 - acc: 0.923 - ETA: 0s - loss: 0.5876 - acc: 0.918 - ETA: 0s - loss: 0.5787 - acc: 0.914 - ETA: 0s - loss: 0.5678 - acc: 0.918 - ETA: 0s - loss: 0.5749 - acc: 0.916 - 0s 498us/step - loss: 0.5742 - acc: 0.9181\n",
      "Epoch 22/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.5873 - acc: 0.875 - ETA: 0s - loss: 0.5666 - acc: 0.921 - ETA: 0s - loss: 0.5622 - acc: 0.918 - ETA: 0s - loss: 0.5110 - acc: 0.932 - ETA: 0s - loss: 0.4995 - acc: 0.933 - ETA: 0s - loss: 0.5042 - acc: 0.935 - ETA: 0s - loss: 0.5062 - acc: 0.931 - ETA: 0s - loss: 0.5060 - acc: 0.935 - 0s 542us/step - loss: 0.5060 - acc: 0.9342\n",
      "Epoch 23/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.3922 - acc: 0.937 - ETA: 0s - loss: 0.4822 - acc: 0.937 - ETA: 0s - loss: 0.4603 - acc: 0.937 - ETA: 0s - loss: 0.4614 - acc: 0.949 - ETA: 0s - loss: 0.4766 - acc: 0.957 - ETA: 0s - loss: 0.4720 - acc: 0.959 - ETA: 0s - loss: 0.4622 - acc: 0.960 - ETA: 0s - loss: 0.4624 - acc: 0.960 - 0s 581us/step - loss: 0.4642 - acc: 0.9615\n",
      "Epoch 24/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.4910 - acc: 0.937 - ETA: 0s - loss: 0.4815 - acc: 0.929 - ETA: 0s - loss: 0.4392 - acc: 0.951 - ETA: 0s - loss: 0.4524 - acc: 0.946 - ETA: 0s - loss: 0.4513 - acc: 0.945 - ETA: 0s - loss: 0.4614 - acc: 0.939 - ETA: 0s - loss: 0.4528 - acc: 0.946 - ETA: 0s - loss: 0.4319 - acc: 0.954 - 0s 558us/step - loss: 0.4266 - acc: 0.9578\n",
      "Epoch 25/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.4147 - acc: 0.906 - ETA: 0s - loss: 0.4382 - acc: 0.946 - ETA: 0s - loss: 0.3819 - acc: 0.958 - ETA: 0s - loss: 0.3834 - acc: 0.954 - ETA: 0s - loss: 0.3847 - acc: 0.954 - ETA: 0s - loss: 0.3991 - acc: 0.950 - 0s 552us/step - loss: 0.4002 - acc: 0.9504\n",
      "Epoch 26/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.3439 - acc: 0.968 - ETA: 0s - loss: 0.3758 - acc: 0.958 - ETA: 0s - loss: 0.3867 - acc: 0.954 - ETA: 0s - loss: 0.3612 - acc: 0.959 - ETA: 0s - loss: 0.3586 - acc: 0.957 - ETA: 0s - loss: 0.3537 - acc: 0.961 - 0s 383us/step - loss: 0.3524 - acc: 0.9615\n",
      "Epoch 27/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.3117 - acc: 1.000 - ETA: 0s - loss: 0.3097 - acc: 0.974 - ETA: 0s - loss: 0.3287 - acc: 0.963 - ETA: 0s - loss: 0.3326 - acc: 0.964 - ETA: 0s - loss: 0.3305 - acc: 0.962 - 0s 331us/step - loss: 0.3337 - acc: 0.9603\n",
      "Epoch 28/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.3125 - acc: 0.968 - ETA: 1s - loss: 0.3249 - acc: 0.953 - ETA: 0s - loss: 0.3043 - acc: 0.959 - ETA: 0s - loss: 0.2967 - acc: 0.968 - ETA: 0s - loss: 0.2959 - acc: 0.966 - ETA: 0s - loss: 0.2900 - acc: 0.968 - ETA: 0s - loss: 0.2851 - acc: 0.971 - ETA: 0s - loss: 0.2809 - acc: 0.971 - ETA: 0s - loss: 0.2784 - acc: 0.971 - 1s 991us/step - loss: 0.2795 - acc: 0.9727\n",
      "Epoch 29/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.2652 - acc: 1.000 - ETA: 0s - loss: 0.2389 - acc: 0.968 - ETA: 0s - loss: 0.2620 - acc: 0.962 - ETA: 0s - loss: 0.2531 - acc: 0.960 - ETA: 0s - loss: 0.2701 - acc: 0.968 - ETA: 0s - loss: 0.2646 - acc: 0.973 - ETA: 0s - loss: 0.2556 - acc: 0.977 - ETA: 0s - loss: 0.2533 - acc: 0.978 - 0s 527us/step - loss: 0.2522 - acc: 0.9789\n",
      "Epoch 30/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.2279 - acc: 1.000 - ETA: 0s - loss: 0.2656 - acc: 0.979 - ETA: 0s - loss: 0.2646 - acc: 0.963 - ETA: 0s - loss: 0.2532 - acc: 0.965 - ETA: 0s - loss: 0.2380 - acc: 0.968 - ETA: 0s - loss: 0.2389 - acc: 0.966 - ETA: 0s - loss: 0.2439 - acc: 0.966 - ETA: 0s - loss: 0.2323 - acc: 0.971 - 0s 596us/step - loss: 0.2345 - acc: 0.9727\n",
      "Epoch 31/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.2451 - acc: 1.000 - ETA: 0s - loss: 0.2192 - acc: 0.991 - ETA: 0s - loss: 0.2291 - acc: 0.985 - ETA: 0s - loss: 0.2219 - acc: 0.984 - ETA: 0s - loss: 0.2146 - acc: 0.983 - ETA: 0s - loss: 0.2064 - acc: 0.982 - ETA: 0s - loss: 0.2097 - acc: 0.981 - ETA: 0s - loss: 0.2127 - acc: 0.979 - ETA: 0s - loss: 0.2135 - acc: 0.979 - 1s 872us/step - loss: 0.2158 - acc: 0.9752\n",
      "Epoch 32/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.2198 - acc: 0.968 - ETA: 0s - loss: 0.1911 - acc: 0.968 - ETA: 0s - loss: 0.2223 - acc: 0.973 - ETA: 0s - loss: 0.2129 - acc: 0.977 - ETA: 0s - loss: 0.2073 - acc: 0.978 - ETA: 0s - loss: 0.2138 - acc: 0.977 - ETA: 0s - loss: 0.2152 - acc: 0.977 - ETA: 0s - loss: 0.2052 - acc: 0.980 - ETA: 0s - loss: 0.2009 - acc: 0.980 - 1s 650us/step - loss: 0.2017 - acc: 0.9801\n",
      "Epoch 33/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1568 - acc: 1.000 - ETA: 0s - loss: 0.1294 - acc: 1.000 - ETA: 0s - loss: 0.1380 - acc: 1.000 - ETA: 0s - loss: 0.1693 - acc: 0.993 - ETA: 0s - loss: 0.1710 - acc: 0.988 - ETA: 0s - loss: 0.1715 - acc: 0.984 - ETA: 0s - loss: 0.1883 - acc: 0.981 - ETA: 0s - loss: 0.1837 - acc: 0.982 - ETA: 0s - loss: 0.1871 - acc: 0.982 - 1s 650us/step - loss: 0.1863 - acc: 0.9814\n",
      "Epoch 34/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1932 - acc: 0.968 - ETA: 0s - loss: 0.1878 - acc: 0.976 - ETA: 0s - loss: 0.1744 - acc: 0.979 - ETA: 0s - loss: 0.1806 - acc: 0.979 - ETA: 0s - loss: 0.1834 - acc: 0.979 - ETA: 0s - loss: 0.1754 - acc: 0.981 - ETA: 0s - loss: 0.1697 - acc: 0.984 - ETA: 0s - loss: 0.1674 - acc: 0.985 - 0s 541us/step - loss: 0.1679 - acc: 0.9851\n",
      "Epoch 35/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1416 - acc: 0.968 - ETA: 1s - loss: 0.0975 - acc: 0.984 - ETA: 0s - loss: 0.1318 - acc: 0.987 - ETA: 0s - loss: 0.1329 - acc: 0.988 - ETA: 0s - loss: 0.1338 - acc: 0.990 - ETA: 0s - loss: 0.1478 - acc: 0.990 - ETA: 0s - loss: 0.1396 - acc: 0.990 - ETA: 0s - loss: 0.1503 - acc: 0.985 - ETA: 0s - loss: 0.1530 - acc: 0.986 - 1s 763us/step - loss: 0.1527 - acc: 0.9864\n",
      "Epoch 36/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1206 - acc: 1.000 - ETA: 0s - loss: 0.1488 - acc: 0.984 - ETA: 0s - loss: 0.1632 - acc: 0.991 - ETA: 0s - loss: 0.1634 - acc: 0.984 - ETA: 0s - loss: 0.1607 - acc: 0.985 - ETA: 0s - loss: 0.1550 - acc: 0.981 - ETA: 0s - loss: 0.1518 - acc: 0.979 - ETA: 0s - loss: 0.1470 - acc: 0.979 - 0s 583us/step - loss: 0.1412 - acc: 0.9814\n",
      "Epoch 37/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1641 - acc: 0.968 - ETA: 0s - loss: 0.1375 - acc: 0.960 - ETA: 0s - loss: 0.1371 - acc: 0.968 - ETA: 0s - loss: 0.1362 - acc: 0.975 - ETA: 0s - loss: 0.1417 - acc: 0.971 - ETA: 0s - loss: 0.1413 - acc: 0.972 - ETA: 0s - loss: 0.1367 - acc: 0.975 - ETA: 0s - loss: 0.1376 - acc: 0.974 - ETA: 0s - loss: 0.1396 - acc: 0.977 - 1s 649us/step - loss: 0.1434 - acc: 0.9777\n",
      "Epoch 38/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1180 - acc: 1.000 - ETA: 0s - loss: 0.1149 - acc: 0.992 - ETA: 0s - loss: 0.1221 - acc: 0.986 - ETA: 0s - loss: 0.1277 - acc: 0.987 - ETA: 0s - loss: 0.1368 - acc: 0.984 - ETA: 0s - loss: 0.1360 - acc: 0.985 - ETA: 0s - loss: 0.1378 - acc: 0.984 - 0s 552us/step - loss: 0.1316 - acc: 0.9851\n",
      "Epoch 39/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1989 - acc: 0.968 - ETA: 0s - loss: 0.1387 - acc: 0.984 - ETA: 0s - loss: 0.1397 - acc: 0.977 - ETA: 0s - loss: 0.1276 - acc: 0.975 - ETA: 0s - loss: 0.1224 - acc: 0.978 - ETA: 0s - loss: 0.1227 - acc: 0.980 - ETA: 0s - loss: 0.1256 - acc: 0.981 - ETA: 0s - loss: 0.1228 - acc: 0.982 - ETA: 0s - loss: 0.1196 - acc: 0.983 - 1s 629us/step - loss: 0.1210 - acc: 0.9839\n",
      "Epoch 40/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0692 - acc: 1.000 - ETA: 0s - loss: 0.1098 - acc: 0.992 - ETA: 0s - loss: 0.1150 - acc: 0.986 - ETA: 0s - loss: 0.1058 - acc: 0.987 - ETA: 0s - loss: 0.1002 - acc: 0.988 - ETA: 0s - loss: 0.0997 - acc: 0.989 - ETA: 0s - loss: 0.1082 - acc: 0.987 - ETA: 0s - loss: 0.1128 - acc: 0.986 - 0s 550us/step - loss: 0.1126 - acc: 0.9864\n",
      "Epoch 41/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1648 - acc: 0.968 - ETA: 0s - loss: 0.1340 - acc: 0.979 - ETA: 0s - loss: 0.1170 - acc: 0.981 - ETA: 0s - loss: 0.1175 - acc: 0.982 - ETA: 0s - loss: 0.1203 - acc: 0.982 - ETA: 0s - loss: 0.1206 - acc: 0.981 - 0s 452us/step - loss: 0.1151 - acc: 0.9839\n",
      "Epoch 42/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0799 - acc: 1.000 - ETA: 0s - loss: 0.1059 - acc: 0.984 - ETA: 0s - loss: 0.1034 - acc: 0.989 - ETA: 0s - loss: 0.1082 - acc: 0.985 - ETA: 0s - loss: 0.1055 - acc: 0.986 - ETA: 0s - loss: 0.0995 - acc: 0.987 - ETA: 0s - loss: 0.1010 - acc: 0.986 - 0s 480us/step - loss: 0.1031 - acc: 0.9876\n",
      "Epoch 43/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0501 - acc: 1.000 - ETA: 0s - loss: 0.0724 - acc: 1.000 - ETA: 0s - loss: 0.1016 - acc: 0.986 - ETA: 0s - loss: 0.1034 - acc: 0.990 - ETA: 0s - loss: 0.0976 - acc: 0.992 - ETA: 0s - loss: 0.0979 - acc: 0.990 - ETA: 0s - loss: 0.1051 - acc: 0.987 - 0s 498us/step - loss: 0.1098 - acc: 0.9864\n",
      "Epoch 44/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1402 - acc: 0.968 - ETA: 0s - loss: 0.0975 - acc: 0.981 - ETA: 0s - loss: 0.1040 - acc: 0.983 - ETA: 0s - loss: 0.1030 - acc: 0.981 - ETA: 0s - loss: 0.1037 - acc: 0.980 - ETA: 0s - loss: 0.1051 - acc: 0.979 - ETA: 0s - loss: 0.1107 - acc: 0.977 - 0s 475us/step - loss: 0.1105 - acc: 0.9777\n",
      "Epoch 45/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0697 - acc: 1.000 - ETA: 0s - loss: 0.1038 - acc: 0.987 - ETA: 0s - loss: 0.0879 - acc: 0.988 - ETA: 0s - loss: 0.0936 - acc: 0.985 - ETA: 0s - loss: 0.0930 - acc: 0.987 - ETA: 0s - loss: 0.0927 - acc: 0.988 - ETA: 0s - loss: 0.0934 - acc: 0.988 - ETA: 0s - loss: 0.0894 - acc: 0.989 - 0s 540us/step - loss: 0.0889 - acc: 0.9901\n",
      "Epoch 46/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0989 - acc: 0.968 - ETA: 0s - loss: 0.0481 - acc: 0.993 - ETA: 0s - loss: 0.0639 - acc: 0.988 - ETA: 0s - loss: 0.0694 - acc: 0.988 - ETA: 0s - loss: 0.0694 - acc: 0.991 - ETA: 0s - loss: 0.0854 - acc: 0.991 - ETA: 0s - loss: 0.0848 - acc: 0.991 - ETA: 0s - loss: 0.0819 - acc: 0.992 - ETA: 0s - loss: 0.0867 - acc: 0.991 - 1s 665us/step - loss: 0.0835 - acc: 0.9913\n",
      "Epoch 47/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0708 - acc: 1.000 - ETA: 0s - loss: 0.0428 - acc: 1.000 - ETA: 0s - loss: 0.0715 - acc: 0.989 - ETA: 0s - loss: 0.0726 - acc: 0.989 - ETA: 0s - loss: 0.0672 - acc: 0.992 - ETA: 0s - loss: 0.0689 - acc: 0.993 - ETA: 0s - loss: 0.0721 - acc: 0.994 - ETA: 0s - loss: 0.0787 - acc: 0.994 - ETA: 0s - loss: 0.0804 - acc: 0.992 - 0s 617us/step - loss: 0.0788 - acc: 0.9926\n",
      "Epoch 48/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1092 - acc: 0.968 - ETA: 0s - loss: 0.0638 - acc: 0.992 - ETA: 0s - loss: 0.0644 - acc: 0.995 - ETA: 0s - loss: 0.0618 - acc: 0.993 - ETA: 0s - loss: 0.0659 - acc: 0.990 - ETA: 0s - loss: 0.0702 - acc: 0.989 - ETA: 0s - loss: 0.0685 - acc: 0.989 - ETA: 0s - loss: 0.0713 - acc: 0.986 - 1s 701us/step - loss: 0.0738 - acc: 0.9864\n",
      "Epoch 49/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.968 - ETA: 0s - loss: 0.0655 - acc: 0.995 - ETA: 0s - loss: 0.0929 - acc: 0.983 - ETA: 0s - loss: 0.0852 - acc: 0.984 - ETA: 0s - loss: 0.0807 - acc: 0.988 - 0s 318us/step - loss: 0.0821 - acc: 0.9876\n",
      "Epoch 50/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1158 - acc: 0.937 - ETA: 0s - loss: 0.0912 - acc: 0.968 - ETA: 0s - loss: 0.0881 - acc: 0.974 - ETA: 0s - loss: 0.0853 - acc: 0.980 - ETA: 0s - loss: 0.0834 - acc: 0.985 - ETA: 0s - loss: 0.0784 - acc: 0.987 - ETA: 0s - loss: 0.0739 - acc: 0.987 - 0s 610us/step - loss: 0.0711 - acc: 0.9876\n",
      "Epoch 51/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0993 - acc: 1.000 - ETA: 0s - loss: 0.0583 - acc: 0.989 - ETA: 0s - loss: 0.0552 - acc: 0.992 - ETA: 0s - loss: 0.0723 - acc: 0.979 - ETA: 0s - loss: 0.0693 - acc: 0.982 - ETA: 0s - loss: 0.0668 - acc: 0.980 - ETA: 0s - loss: 0.0694 - acc: 0.983 - 0s 511us/step - loss: 0.0672 - acc: 0.9839\n",
      "Epoch 52/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1269 - acc: 0.968 - ETA: 0s - loss: 0.0994 - acc: 0.976 - ETA: 0s - loss: 0.0839 - acc: 0.986 - ETA: 0s - loss: 0.0809 - acc: 0.987 - ETA: 0s - loss: 0.0723 - acc: 0.991 - ETA: 0s - loss: 0.0712 - acc: 0.990 - ETA: 0s - loss: 0.0695 - acc: 0.992 - ETA: 0s - loss: 0.0638 - acc: 0.993 - 0s 538us/step - loss: 0.0650 - acc: 0.9926\n",
      "Epoch 53/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0310 - acc: 1.000 - ETA: 0s - loss: 0.0351 - acc: 1.000 - ETA: 0s - loss: 0.0540 - acc: 0.995 - ETA: 0s - loss: 0.0523 - acc: 0.996 - ETA: 0s - loss: 0.0657 - acc: 0.990 - ETA: 0s - loss: 0.0698 - acc: 0.990 - ETA: 0s - loss: 0.0657 - acc: 0.992 - ETA: 0s - loss: 0.0649 - acc: 0.992 - 0s 524us/step - loss: 0.0647 - acc: 0.9913\n",
      "Epoch 54/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0871 - acc: 1.000 - ETA: 0s - loss: 0.0548 - acc: 1.000 - ETA: 0s - loss: 0.0478 - acc: 1.000 - ETA: 0s - loss: 0.0627 - acc: 0.994 - ETA: 0s - loss: 0.0589 - acc: 0.995 - ETA: 0s - loss: 0.0580 - acc: 0.994 - ETA: 0s - loss: 0.0541 - acc: 0.995 - ETA: 0s - loss: 0.0544 - acc: 0.994 - ETA: 0s - loss: 0.0540 - acc: 0.993 - 1s 645us/step - loss: 0.0536 - acc: 0.9938\n",
      "Epoch 55/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0576 - acc: 1.000 - ETA: 0s - loss: 0.0714 - acc: 0.987 - ETA: 0s - loss: 0.0658 - acc: 0.992 - ETA: 0s - loss: 0.0577 - acc: 0.992 - ETA: 0s - loss: 0.0581 - acc: 0.989 - ETA: 0s - loss: 0.0564 - acc: 0.991 - ETA: 0s - loss: 0.0558 - acc: 0.992 - ETA: 0s - loss: 0.0541 - acc: 0.993 - 0s 546us/step - loss: 0.0537 - acc: 0.9938\n",
      "Epoch 56/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0754 - acc: 1.000 - ETA: 0s - loss: 0.0711 - acc: 0.981 - ETA: 0s - loss: 0.0731 - acc: 0.979 - ETA: 0s - loss: 0.0649 - acc: 0.981 - ETA: 0s - loss: 0.0717 - acc: 0.981 - ETA: 0s - loss: 0.0647 - acc: 0.985 - ETA: 0s - loss: 0.0611 - acc: 0.987 - ETA: 0s - loss: 0.0618 - acc: 0.987 - 0s 577us/step - loss: 0.0617 - acc: 0.9876\n",
      "Epoch 57/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0664 - acc: 1.000 - ETA: 0s - loss: 0.0673 - acc: 0.992 - ETA: 0s - loss: 0.0881 - acc: 0.986 - ETA: 0s - loss: 0.0684 - acc: 0.988 - ETA: 0s - loss: 0.0675 - acc: 0.985 - ETA: 0s - loss: 0.0620 - acc: 0.987 - ETA: 0s - loss: 0.0597 - acc: 0.989 - ETA: 0s - loss: 0.0603 - acc: 0.990 - ETA: 0s - loss: 0.0626 - acc: 0.987 - 1s 660us/step - loss: 0.0622 - acc: 0.9876\n",
      "Epoch 58/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0375 - acc: 1.000 - ETA: 0s - loss: 0.0359 - acc: 1.000 - ETA: 0s - loss: 0.0342 - acc: 1.000 - ETA: 0s - loss: 0.0415 - acc: 0.995 - ETA: 0s - loss: 0.0457 - acc: 0.996 - ETA: 0s - loss: 0.0469 - acc: 0.997 - ETA: 0s - loss: 0.0462 - acc: 0.996 - 0s 598us/step - loss: 0.0475 - acc: 0.9950\n",
      "Epoch 59/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0148 - acc: 1.000 - ETA: 0s - loss: 0.0549 - acc: 0.991 - ETA: 0s - loss: 0.0491 - acc: 0.992 - ETA: 0s - loss: 0.0470 - acc: 0.992 - ETA: 0s - loss: 0.0484 - acc: 0.992 - ETA: 0s - loss: 0.0436 - acc: 0.993 - ETA: 0s - loss: 0.0465 - acc: 0.990 - ETA: 0s - loss: 0.0474 - acc: 0.987 - 1s 711us/step - loss: 0.0474 - acc: 0.9876\n",
      "Epoch 60/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0911 - acc: 0.968 - ETA: 0s - loss: 0.0721 - acc: 0.984 - ETA: 0s - loss: 0.0512 - acc: 0.991 - ETA: 0s - loss: 0.0400 - acc: 0.993 - ETA: 0s - loss: 0.0369 - acc: 0.994 - ETA: 0s - loss: 0.0381 - acc: 0.992 - ETA: 0s - loss: 0.0398 - acc: 0.993 - ETA: 0s - loss: 0.0395 - acc: 0.994 - ETA: 0s - loss: 0.0380 - acc: 0.993 - ETA: 0s - loss: 0.0368 - acc: 0.994 - 1s 1ms/step - loss: 0.0426 - acc: 0.9913\n",
      "Epoch 61/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0423 - acc: 1.000 - ETA: 0s - loss: 0.0365 - acc: 1.000 - ETA: 0s - loss: 0.0444 - acc: 1.000 - ETA: 0s - loss: 0.0408 - acc: 0.996 - ETA: 0s - loss: 0.0354 - acc: 0.995 - ETA: 0s - loss: 0.0416 - acc: 0.990 - ETA: 0s - loss: 0.0389 - acc: 0.991 - ETA: 0s - loss: 0.0427 - acc: 0.991 - ETA: 0s - loss: 0.0437 - acc: 0.991 - 1s 697us/step - loss: 0.0434 - acc: 0.9913\n",
      "Epoch 62/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.1140 - acc: 0.968 - ETA: 0s - loss: 0.0622 - acc: 0.992 - ETA: 0s - loss: 0.0580 - acc: 0.995 - ETA: 0s - loss: 0.0548 - acc: 0.996 - ETA: 0s - loss: 0.0527 - acc: 0.997 - ETA: 0s - loss: 0.0516 - acc: 0.995 - ETA: 0s - loss: 0.0489 - acc: 0.994 - ETA: 0s - loss: 0.0508 - acc: 0.995 - ETA: 0s - loss: 0.0489 - acc: 0.994 - 1s 659us/step - loss: 0.0503 - acc: 0.9938\n",
      "Epoch 63/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0402 - acc: 1.000 - ETA: 0s - loss: 0.0343 - acc: 1.000 - ETA: 0s - loss: 0.0293 - acc: 0.995 - ETA: 0s - loss: 0.0415 - acc: 0.990 - ETA: 0s - loss: 0.0399 - acc: 0.992 - ETA: 0s - loss: 0.0381 - acc: 0.992 - ETA: 0s - loss: 0.0407 - acc: 0.991 - ETA: 0s - loss: 0.0394 - acc: 0.992 - ETA: 0s - loss: 0.0394 - acc: 0.992 - 1s 638us/step - loss: 0.0400 - acc: 0.9926\n",
      "Epoch 64/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0223 - acc: 1.000 - ETA: 0s - loss: 0.0444 - acc: 1.000 - ETA: 0s - loss: 0.0594 - acc: 0.995 - ETA: 0s - loss: 0.0603 - acc: 0.996 - ETA: 0s - loss: 0.0532 - acc: 0.997 - ETA: 0s - loss: 0.0507 - acc: 0.995 - ETA: 0s - loss: 0.0518 - acc: 0.994 - ETA: 0s - loss: 0.0525 - acc: 0.993 - ETA: 0s - loss: 0.0493 - acc: 0.994 - ETA: 0s - loss: 0.0452 - acc: 0.994 - 1s 721us/step - loss: 0.0458 - acc: 0.9938\n",
      "Epoch 65/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0090 - acc: 1.000 - ETA: 0s - loss: 0.0669 - acc: 0.976 - ETA: 0s - loss: 0.0542 - acc: 0.986 - ETA: 0s - loss: 0.0519 - acc: 0.988 - ETA: 0s - loss: 0.0570 - acc: 0.988 - ETA: 0s - loss: 0.0505 - acc: 0.989 - 0s 426us/step - loss: 0.0499 - acc: 0.9888\n",
      "Epoch 66/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0359 - acc: 1.000 - ETA: 0s - loss: 0.0462 - acc: 0.987 - ETA: 0s - loss: 0.0425 - acc: 0.989 - ETA: 0s - loss: 0.0430 - acc: 0.989 - ETA: 0s - loss: 0.0426 - acc: 0.991 - ETA: 0s - loss: 0.0454 - acc: 0.989 - ETA: 0s - loss: 0.0430 - acc: 0.991 - ETA: 0s - loss: 0.0396 - acc: 0.992 - 0s 617us/step - loss: 0.0392 - acc: 0.9926\n",
      "Epoch 67/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0118 - acc: 1.000 - ETA: 0s - loss: 0.0237 - acc: 0.992 - ETA: 0s - loss: 0.0532 - acc: 0.982 - ETA: 0s - loss: 0.0551 - acc: 0.987 - ETA: 0s - loss: 0.0494 - acc: 0.989 - ETA: 0s - loss: 0.0557 - acc: 0.987 - ETA: 0s - loss: 0.0497 - acc: 0.989 - ETA: 0s - loss: 0.0485 - acc: 0.989 - ETA: 0s - loss: 0.0457 - acc: 0.990 - 1s 643us/step - loss: 0.0456 - acc: 0.9913\n",
      "Epoch 68/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0245 - acc: 1.000 - ETA: 0s - loss: 0.0320 - acc: 1.000 - ETA: 0s - loss: 0.0348 - acc: 1.000 - ETA: 0s - loss: 0.0393 - acc: 1.000 - ETA: 0s - loss: 0.0371 - acc: 1.000 - ETA: 0s - loss: 0.0404 - acc: 0.997 - ETA: 0s - loss: 0.0371 - acc: 0.998 - ETA: 0s - loss: 0.0385 - acc: 0.998 - ETA: 0s - loss: 0.0395 - acc: 0.998 - 1s 701us/step - loss: 0.0393 - acc: 0.9988\n",
      "Epoch 69/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.000 - ETA: 0s - loss: 0.0142 - acc: 1.000 - ETA: 0s - loss: 0.0293 - acc: 0.995 - ETA: 0s - loss: 0.0241 - acc: 0.996 - ETA: 0s - loss: 0.0236 - acc: 0.997 - ETA: 0s - loss: 0.0280 - acc: 0.994 - ETA: 0s - loss: 0.0343 - acc: 0.991 - ETA: 0s - loss: 0.0336 - acc: 0.992 - ETA: 0s - loss: 0.0329 - acc: 0.993 - 1s 645us/step - loss: 0.0327 - acc: 0.9938\n",
      "Epoch 70/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.000 - ETA: 0s - loss: 0.0147 - acc: 1.000 - ETA: 0s - loss: 0.0213 - acc: 1.000 - ETA: 0s - loss: 0.0320 - acc: 0.992 - ETA: 0s - loss: 0.0317 - acc: 0.993 - ETA: 0s - loss: 0.0323 - acc: 0.995 - ETA: 0s - loss: 0.0321 - acc: 0.995 - ETA: 0s - loss: 0.0384 - acc: 0.992 - ETA: 0s - loss: 0.0359 - acc: 0.993 - ETA: 0s - loss: 0.0360 - acc: 0.993 - 1s 736us/step - loss: 0.0355 - acc: 0.9938\n",
      "Epoch 71/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - ETA: 0s - loss: 0.0157 - acc: 1.000 - ETA: 0s - loss: 0.0399 - acc: 0.995 - ETA: 0s - loss: 0.0424 - acc: 0.993 - ETA: 0s - loss: 0.0459 - acc: 0.994 - ETA: 0s - loss: 0.0461 - acc: 0.993 - ETA: 0s - loss: 0.0453 - acc: 0.991 - ETA: 0s - loss: 0.0420 - acc: 0.992 - ETA: 0s - loss: 0.0381 - acc: 0.993 - 1s 645us/step - loss: 0.0379 - acc: 0.9938\n",
      "Epoch 72/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0117 - acc: 1.000 - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.0183 - acc: 1.000 - ETA: 0s - loss: 0.0225 - acc: 1.000 - ETA: 0s - loss: 0.0295 - acc: 0.995 - ETA: 0s - loss: 0.0376 - acc: 0.992 - ETA: 0s - loss: 0.0353 - acc: 0.993 - ETA: 0s - loss: 0.0333 - acc: 0.994 - ETA: 0s - loss: 0.0351 - acc: 0.994 - ETA: 0s - loss: 0.0342 - acc: 0.995 - 1s 779us/step - loss: 0.0340 - acc: 0.9950\n",
      "Epoch 73/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0246 - acc: 1.000 - ETA: 0s - loss: 0.0269 - acc: 1.000 - ETA: 0s - loss: 0.0230 - acc: 1.000 - ETA: 0s - loss: 0.0325 - acc: 0.996 - ETA: 0s - loss: 0.0369 - acc: 0.997 - ETA: 0s - loss: 0.0358 - acc: 0.997 - ETA: 0s - loss: 0.0333 - acc: 0.998 - ETA: 0s - loss: 0.0364 - acc: 0.996 - ETA: 0s - loss: 0.0328 - acc: 0.997 - ETA: 0s - loss: 0.0344 - acc: 0.995 - ETA: 0s - loss: 0.0346 - acc: 0.994 - ETA: 0s - loss: 0.0339 - acc: 0.995 - 1s 921us/step - loss: 0.0338 - acc: 0.9950\n",
      "Epoch 74/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0516 - acc: 1.000 - ETA: 0s - loss: 0.0603 - acc: 0.968 - ETA: 0s - loss: 0.0535 - acc: 0.979 - ETA: 0s - loss: 0.0413 - acc: 0.986 - ETA: 0s - loss: 0.0441 - acc: 0.987 - ETA: 0s - loss: 0.0399 - acc: 0.989 - ETA: 0s - loss: 0.0394 - acc: 0.991 - ETA: 0s - loss: 0.0376 - acc: 0.991 - ETA: 0s - loss: 0.0379 - acc: 0.990 - 1s 648us/step - loss: 0.0377 - acc: 0.9913\n",
      "Epoch 75/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0389 - acc: 1.000 - ETA: 0s - loss: 0.0238 - acc: 1.000 - ETA: 0s - loss: 0.0253 - acc: 1.000 - ETA: 0s - loss: 0.0288 - acc: 0.996 - ETA: 0s - loss: 0.0261 - acc: 0.997 - ETA: 0s - loss: 0.0331 - acc: 0.994 - ETA: 0s - loss: 0.0295 - acc: 0.995 - ETA: 0s - loss: 0.0279 - acc: 0.995 - ETA: 0s - loss: 0.0281 - acc: 0.996 - 1s 625us/step - loss: 0.0280 - acc: 0.9963\n",
      "Epoch 76/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0453 - acc: 1.000 - ETA: 0s - loss: 0.0790 - acc: 0.984 - ETA: 0s - loss: 0.0536 - acc: 0.986 - ETA: 0s - loss: 0.0520 - acc: 0.986 - ETA: 0s - loss: 0.0468 - acc: 0.989 - ETA: 0s - loss: 0.0427 - acc: 0.991 - ETA: 0s - loss: 0.0466 - acc: 0.990 - ETA: 0s - loss: 0.0438 - acc: 0.992 - ETA: 0s - loss: 0.0412 - acc: 0.992 - ETA: 0s - loss: 0.0411 - acc: 0.992 - 1s 828us/step - loss: 0.0410 - acc: 0.9926\n",
      "Epoch 77/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0156 - acc: 1.000 - ETA: 0s - loss: 0.0144 - acc: 1.000 - ETA: 0s - loss: 0.0319 - acc: 0.992 - ETA: 0s - loss: 0.0260 - acc: 0.994 - ETA: 0s - loss: 0.0291 - acc: 0.995 - ETA: 0s - loss: 0.0313 - acc: 0.994 - ETA: 0s - loss: 0.0283 - acc: 0.995 - ETA: 0s - loss: 0.0299 - acc: 0.995 - 0s 573us/step - loss: 0.0295 - acc: 0.9963\n",
      "Epoch 78/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0089 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0163 - acc: 1.000 - ETA: 0s - loss: 0.0172 - acc: 1.000 - ETA: 0s - loss: 0.0196 - acc: 0.998 - ETA: 0s - loss: 0.0246 - acc: 0.996 - 0s 537us/step - loss: 0.0248 - acc: 0.9963\n",
      "Epoch 79/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - ETA: 0s - loss: 0.0270 - acc: 1.000 - ETA: 0s - loss: 0.0310 - acc: 0.997 - ETA: 0s - loss: 0.0321 - acc: 0.995 - ETA: 0s - loss: 0.0298 - acc: 0.996 - ETA: 0s - loss: 0.0367 - acc: 0.995 - ETA: 0s - loss: 0.0336 - acc: 0.995 - ETA: 0s - loss: 0.0367 - acc: 0.993 - 0s 533us/step - loss: 0.0365 - acc: 0.9938\n",
      "Epoch 80/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0516 - acc: 1.000 - ETA: 0s - loss: 0.0576 - acc: 0.979 - ETA: 0s - loss: 0.0422 - acc: 0.987 - ETA: 0s - loss: 0.0442 - acc: 0.989 - ETA: 0s - loss: 0.0464 - acc: 0.987 - ETA: 0s - loss: 0.0470 - acc: 0.988 - 0s 373us/step - loss: 0.0469 - acc: 0.9888\n",
      "Epoch 81/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0149 - acc: 1.000 - ETA: 0s - loss: 0.0394 - acc: 0.993 - ETA: 0s - loss: 0.0400 - acc: 0.990 - ETA: 0s - loss: 0.0355 - acc: 0.993 - ETA: 0s - loss: 0.0323 - acc: 0.993 - ETA: 0s - loss: 0.0298 - acc: 0.995 - 0s 400us/step - loss: 0.0298 - acc: 0.9950\n",
      "Epoch 82/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0228 - acc: 1.000 - ETA: 0s - loss: 0.0191 - acc: 1.000 - ETA: 0s - loss: 0.0200 - acc: 0.998 - ETA: 0s - loss: 0.0202 - acc: 0.998 - ETA: 0s - loss: 0.0221 - acc: 0.997 - 0s 383us/step - loss: 0.0220 - acc: 0.9975\n",
      "Epoch 83/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0352 - acc: 1.000 - ETA: 0s - loss: 0.0373 - acc: 0.989 - ETA: 0s - loss: 0.0405 - acc: 0.993 - ETA: 0s - loss: 0.0344 - acc: 0.993 - ETA: 0s - loss: 0.0339 - acc: 0.993 - ETA: 0s - loss: 0.0336 - acc: 0.993 - 0s 375us/step - loss: 0.0335 - acc: 0.9938\n",
      "Epoch 84/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0316 - acc: 1.000 - ETA: 0s - loss: 0.0198 - acc: 1.000 - ETA: 0s - loss: 0.0158 - acc: 1.000 - ETA: 0s - loss: 0.0177 - acc: 0.997 - ETA: 0s - loss: 0.0172 - acc: 0.998 - ETA: 0s - loss: 0.0183 - acc: 0.998 - 0s 444us/step - loss: 0.0191 - acc: 0.9988\n",
      "Epoch 85/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0127 - acc: 1.000 - ETA: 0s - loss: 0.0142 - acc: 1.000 - ETA: 0s - loss: 0.0237 - acc: 0.997 - ETA: 0s - loss: 0.0224 - acc: 0.998 - ETA: 0s - loss: 0.0273 - acc: 0.995 - 0s 331us/step - loss: 0.0281 - acc: 0.9950\n",
      "Epoch 86/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0161 - acc: 1.000 - ETA: 0s - loss: 0.0143 - acc: 1.000 - ETA: 0s - loss: 0.0215 - acc: 1.000 - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.0254 - acc: 0.996 - ETA: 0s - loss: 0.0267 - acc: 0.995 - 0s 392us/step - loss: 0.0255 - acc: 0.9963\n",
      "Epoch 87/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0290 - acc: 0.991 - ETA: 0s - loss: 0.0387 - acc: 0.989 - ETA: 0s - loss: 0.0331 - acc: 0.990 - ETA: 0s - loss: 0.0316 - acc: 0.991 - 0s 341us/step - loss: 0.0332 - acc: 0.9913\n",
      "Epoch 88/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0299 - acc: 0.989 - ETA: 0s - loss: 0.0270 - acc: 0.993 - ETA: 0s - loss: 0.0311 - acc: 0.994 - ETA: 0s - loss: 0.0292 - acc: 0.995 - ETA: 0s - loss: 0.0276 - acc: 0.996 - ETA: 0s - loss: 0.0277 - acc: 0.997 - ETA: 0s - loss: 0.0291 - acc: 0.996 - 0s 571us/step - loss: 0.0300 - acc: 0.9963\n",
      "Epoch 89/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0194 - acc: 0.989 - ETA: 0s - loss: 0.0251 - acc: 0.989 - ETA: 0s - loss: 0.0214 - acc: 0.993 - ETA: 0s - loss: 0.0283 - acc: 0.989 - ETA: 0s - loss: 0.0260 - acc: 0.991 - ETA: 0s - loss: 0.0239 - acc: 0.993 - ETA: 0s - loss: 0.0251 - acc: 0.992 - ETA: 0s - loss: 0.0251 - acc: 0.993 - 1s 873us/step - loss: 0.0242 - acc: 0.9938\n",
      "Epoch 90/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0154 - acc: 1.000 - ETA: 0s - loss: 0.0111 - acc: 1.000 - ETA: 0s - loss: 0.0231 - acc: 0.992 - ETA: 0s - loss: 0.0193 - acc: 0.994 - ETA: 0s - loss: 0.0205 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.994 - ETA: 0s - loss: 0.0233 - acc: 0.991 - ETA: 0s - loss: 0.0241 - acc: 0.992 - ETA: 0s - loss: 0.0248 - acc: 0.993 - 1s 852us/step - loss: 0.0240 - acc: 0.9938\n",
      "Epoch 91/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0084 - acc: 1.000 - ETA: 0s - loss: 0.0337 - acc: 0.992 - ETA: 0s - loss: 0.0279 - acc: 0.995 - ETA: 0s - loss: 0.0228 - acc: 0.996 - ETA: 0s - loss: 0.0220 - acc: 0.995 - ETA: 0s - loss: 0.0186 - acc: 0.996 - ETA: 0s - loss: 0.0172 - acc: 0.996 - ETA: 0s - loss: 0.0165 - acc: 0.997 - ETA: 0s - loss: 0.0156 - acc: 0.997 - 1s 632us/step - loss: 0.0157 - acc: 0.9975\n",
      "Epoch 92/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0527 - acc: 0.968 - ETA: 2s - loss: 0.0360 - acc: 0.984 - ETA: 1s - loss: 0.0459 - acc: 0.981 - ETA: 0s - loss: 0.0362 - acc: 0.988 - ETA: 0s - loss: 0.0325 - acc: 0.991 - ETA: 0s - loss: 0.0316 - acc: 0.991 - ETA: 0s - loss: 0.0301 - acc: 0.991 - ETA: 0s - loss: 0.0309 - acc: 0.991 - ETA: 0s - loss: 0.0314 - acc: 0.991 - ETA: 0s - loss: 0.0284 - acc: 0.992 - ETA: 0s - loss: 0.0269 - acc: 0.993 - 1s 1ms/step - loss: 0.0267 - acc: 0.9938\n",
      "Epoch 93/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0177 - acc: 1.000 - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0144 - acc: 1.000 - ETA: 0s - loss: 0.0131 - acc: 1.000 - ETA: 0s - loss: 0.0124 - acc: 1.000 - ETA: 0s - loss: 0.0113 - acc: 1.000 - ETA: 0s - loss: 0.0106 - acc: 1.000 - ETA: 0s - loss: 0.0105 - acc: 1.000 - ETA: 0s - loss: 0.0169 - acc: 0.995 - 1s 903us/step - loss: 0.0173 - acc: 0.9963\n",
      "Epoch 94/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0078 - acc: 1.000 - ETA: 0s - loss: 0.0074 - acc: 1.000 - ETA: 1s - loss: 0.0060 - acc: 1.000 - ETA: 0s - loss: 0.0146 - acc: 1.000 - ETA: 0s - loss: 0.0116 - acc: 1.000 - ETA: 0s - loss: 0.0149 - acc: 0.997 - ETA: 0s - loss: 0.0174 - acc: 0.998 - ETA: 0s - loss: 0.0190 - acc: 0.996 - ETA: 0s - loss: 0.0173 - acc: 0.997 - ETA: 0s - loss: 0.0172 - acc: 0.997 - 1s 996us/step - loss: 0.0175 - acc: 0.9975\n",
      "Epoch 95/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0078 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0126 - acc: 1.000 - ETA: 0s - loss: 0.0147 - acc: 1.000 - ETA: 0s - loss: 0.0215 - acc: 0.994 - ETA: 0s - loss: 0.0229 - acc: 0.993 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0231 - acc: 0.995 - ETA: 0s - loss: 0.0227 - acc: 0.995 - ETA: 0s - loss: 0.0219 - acc: 0.995 - 1s 867us/step - loss: 0.0228 - acc: 0.9950\n",
      "Epoch 96/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0128 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0078 - acc: 1.000 - ETA: 0s - loss: 0.0095 - acc: 1.000 - ETA: 0s - loss: 0.0125 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 0.998 - ETA: 0s - loss: 0.0153 - acc: 0.998 - ETA: 0s - loss: 0.0151 - acc: 0.998 - ETA: 0s - loss: 0.0159 - acc: 0.998 - ETA: 0s - loss: 0.0155 - acc: 0.998 - 1s 828us/step - loss: 0.0160 - acc: 0.9988\n",
      "Epoch 97/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0100 - acc: 1.000 - ETA: 0s - loss: 0.0325 - acc: 0.989 - ETA: 0s - loss: 0.0243 - acc: 0.994 - ETA: 0s - loss: 0.0197 - acc: 0.996 - ETA: 0s - loss: 0.0261 - acc: 0.992 - ETA: 0s - loss: 0.0264 - acc: 0.992 - ETA: 0s - loss: 0.0252 - acc: 0.992 - ETA: 0s - loss: 0.0222 - acc: 0.993 - ETA: 0s - loss: 0.0215 - acc: 0.994 - 1s 985us/step - loss: 0.0203 - acc: 0.9950\n",
      "Epoch 98/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0229 - acc: 1.000 - ETA: 2s - loss: 0.0359 - acc: 1.000 - ETA: 1s - loss: 0.0245 - acc: 1.000 - ETA: 0s - loss: 0.0294 - acc: 0.994 - ETA: 0s - loss: 0.0257 - acc: 0.996 - ETA: 0s - loss: 0.0279 - acc: 0.993 - ETA: 0s - loss: 0.0249 - acc: 0.994 - ETA: 0s - loss: 0.0227 - acc: 0.995 - 1s 738us/step - loss: 0.0217 - acc: 0.9963\n",
      "Epoch 99/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0787 - acc: 0.968 - ETA: 0s - loss: 0.0430 - acc: 0.992 - ETA: 0s - loss: 0.0374 - acc: 0.991 - ETA: 0s - loss: 0.0365 - acc: 0.992 - ETA: 0s - loss: 0.0270 - acc: 0.994 - ETA: 0s - loss: 0.0245 - acc: 0.995 - ETA: 0s - loss: 0.0207 - acc: 0.996 - ETA: 0s - loss: 0.0201 - acc: 0.996 - ETA: 0s - loss: 0.0206 - acc: 0.995 - ETA: 0s - loss: 0.0195 - acc: 0.994 - 1s 732us/step - loss: 0.0190 - acc: 0.9950\n",
      "Epoch 100/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0196 - acc: 1.000 - ETA: 0s - loss: 0.0136 - acc: 1.000 - ETA: 0s - loss: 0.0182 - acc: 0.993 - ETA: 0s - loss: 0.0129 - acc: 0.996 - ETA: 0s - loss: 0.0152 - acc: 0.997 - ETA: 0s - loss: 0.0213 - acc: 0.993 - ETA: 0s - loss: 0.0195 - acc: 0.994 - ETA: 0s - loss: 0.0185 - acc: 0.994 - ETA: 0s - loss: 0.0190 - acc: 0.995 - ETA: 0s - loss: 0.0222 - acc: 0.995 - 1s 679us/step - loss: 0.0221 - acc: 0.9950\n",
      "Epoch 101/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0155 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0247 - acc: 1.000 - ETA: 0s - loss: 0.0194 - acc: 1.000 - ETA: 0s - loss: 0.0193 - acc: 1.000 - ETA: 0s - loss: 0.0193 - acc: 1.000 - ETA: 0s - loss: 0.0251 - acc: 0.996 - ETA: 0s - loss: 0.0228 - acc: 0.997 - 0s 553us/step - loss: 0.0225 - acc: 0.9975\n",
      "Epoch 102/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0467 - acc: 1.000 - ETA: 0s - loss: 0.0396 - acc: 0.993 - ETA: 0s - loss: 0.0264 - acc: 0.996 - ETA: 0s - loss: 0.0256 - acc: 0.995 - ETA: 0s - loss: 0.0242 - acc: 0.996 - ETA: 0s - loss: 0.0220 - acc: 0.997 - 0s 408us/step - loss: 0.0207 - acc: 0.9975\n",
      "Epoch 103/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0317 - acc: 1.000 - ETA: 0s - loss: 0.0230 - acc: 0.994 - ETA: 0s - loss: 0.0230 - acc: 0.997 - ETA: 0s - loss: 0.0201 - acc: 0.997 - ETA: 0s - loss: 0.0231 - acc: 0.996 - ETA: 0s - loss: 0.0241 - acc: 0.995 - ETA: 0s - loss: 0.0273 - acc: 0.995 - 0s 468us/step - loss: 0.0271 - acc: 0.9950\n",
      "Epoch 104/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0253 - acc: 0.992 - ETA: 0s - loss: 0.0152 - acc: 0.996 - ETA: 0s - loss: 0.0152 - acc: 0.997 - ETA: 0s - loss: 0.0159 - acc: 0.998 - ETA: 0s - loss: 0.0202 - acc: 0.996 - ETA: 0s - loss: 0.0177 - acc: 0.997 - 0s 433us/step - loss: 0.0172 - acc: 0.9975\n",
      "Epoch 105/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - ETA: 0s - loss: 0.0123 - acc: 1.000 - ETA: 0s - loss: 0.0109 - acc: 1.000 - ETA: 0s - loss: 0.0154 - acc: 0.995 - ETA: 0s - loss: 0.0159 - acc: 0.994 - ETA: 0s - loss: 0.0158 - acc: 0.995 - 0s 429us/step - loss: 0.0150 - acc: 0.9963\n",
      "Epoch 106/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0129 - acc: 0.993 - ETA: 0s - loss: 0.0139 - acc: 0.993 - ETA: 0s - loss: 0.0154 - acc: 0.992 - ETA: 0s - loss: 0.0194 - acc: 0.992 - ETA: 0s - loss: 0.0189 - acc: 0.992 - ETA: 0s - loss: 0.0182 - acc: 0.993 - 0s 459us/step - loss: 0.0181 - acc: 0.9938\n",
      "Epoch 107/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0099 - acc: 1.000 - ETA: 0s - loss: 0.0355 - acc: 0.992 - ETA: 0s - loss: 0.0210 - acc: 0.996 - ETA: 0s - loss: 0.0312 - acc: 0.992 - ETA: 0s - loss: 0.0258 - acc: 0.994 - ETA: 0s - loss: 0.0238 - acc: 0.994 - 0s 434us/step - loss: 0.0228 - acc: 0.9938\n",
      "Epoch 108/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0063 - acc: 1.000 - ETA: 0s - loss: 0.0199 - acc: 1.000 - ETA: 0s - loss: 0.0219 - acc: 0.996 - ETA: 0s - loss: 0.0215 - acc: 0.994 - ETA: 0s - loss: 0.0201 - acc: 0.996 - ETA: 0s - loss: 0.0193 - acc: 0.995 - 0s 434us/step - loss: 0.0179 - acc: 0.9963\n",
      "Epoch 109/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0214 - acc: 1.000 - ETA: 0s - loss: 0.0119 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 1.000 - ETA: 0s - loss: 0.0129 - acc: 1.000 - ETA: 0s - loss: 0.0177 - acc: 0.996 - ETA: 0s - loss: 0.0173 - acc: 0.996 - ETA: 0s - loss: 0.0173 - acc: 0.997 - 0s 459us/step - loss: 0.0166 - acc: 0.9975\n",
      "Epoch 110/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0122 - acc: 0.993 - ETA: 0s - loss: 0.0132 - acc: 0.996 - ETA: 0s - loss: 0.0145 - acc: 0.997 - ETA: 0s - loss: 0.0176 - acc: 0.996 - ETA: 0s - loss: 0.0162 - acc: 0.997 - ETA: 0s - loss: 0.0148 - acc: 0.997 - 0s 444us/step - loss: 0.0147 - acc: 0.9975\n",
      "Epoch 111/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0197 - acc: 0.987 - ETA: 0s - loss: 0.0152 - acc: 0.992 - ETA: 0s - loss: 0.0140 - acc: 0.994 - ETA: 0s - loss: 0.0119 - acc: 0.996 - ETA: 0s - loss: 0.0125 - acc: 0.996 - ETA: 0s - loss: 0.0123 - acc: 0.997 - 0s 499us/step - loss: 0.0124 - acc: 0.9975\n",
      "Epoch 112/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0174 - acc: 0.996 - ETA: 0s - loss: 0.0214 - acc: 0.995 - ETA: 0s - loss: 0.0182 - acc: 0.996 - ETA: 0s - loss: 0.0225 - acc: 0.992 - ETA: 0s - loss: 0.0216 - acc: 0.992 - 0s 555us/step - loss: 0.0228 - acc: 0.9913\n",
      "Epoch 113/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0049 - acc: 1.000 - ETA: 0s - loss: 0.0166 - acc: 1.000 - ETA: 0s - loss: 0.0216 - acc: 0.994 - ETA: 0s - loss: 0.0183 - acc: 0.996 - ETA: 0s - loss: 0.0191 - acc: 0.997 - ETA: 0s - loss: 0.0166 - acc: 0.998 - ETA: 0s - loss: 0.0240 - acc: 0.995 - ETA: 0s - loss: 0.0245 - acc: 0.995 - 0s 553us/step - loss: 0.0238 - acc: 0.9950\n",
      "Epoch 114/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.000 - ETA: 0s - loss: 0.0205 - acc: 1.000 - ETA: 0s - loss: 0.0154 - acc: 1.000 - ETA: 0s - loss: 0.0151 - acc: 1.000 - ETA: 0s - loss: 0.0172 - acc: 1.000 - ETA: 0s - loss: 0.0193 - acc: 0.996 - ETA: 0s - loss: 0.0192 - acc: 0.995 - ETA: 0s - loss: 0.0188 - acc: 0.994 - 0s 543us/step - loss: 0.0181 - acc: 0.9950\n",
      "Epoch 115/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0103 - acc: 1.000 - ETA: 0s - loss: 0.0078 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - ETA: 0s - loss: 0.0095 - acc: 1.000 - ETA: 0s - loss: 0.0090 - acc: 1.000 - ETA: 0s - loss: 0.0079 - acc: 1.000 - ETA: 0s - loss: 0.0095 - acc: 1.000 - ETA: 0s - loss: 0.0099 - acc: 1.000 - 0s 551us/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - ETA: 0s - loss: 0.0388 - acc: 0.984 - ETA: 0s - loss: 0.0263 - acc: 0.991 - ETA: 0s - loss: 0.0239 - acc: 0.991 - ETA: 0s - loss: 0.0224 - acc: 0.991 - ETA: 0s - loss: 0.0200 - acc: 0.993 - ETA: 0s - loss: 0.0247 - acc: 0.991 - ETA: 0s - loss: 0.0222 - acc: 0.992 - 0s 535us/step - loss: 0.0221 - acc: 0.9926\n",
      "Epoch 117/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0057 - acc: 1.000 - ETA: 0s - loss: 0.0185 - acc: 0.997 - ETA: 0s - loss: 0.0158 - acc: 0.997 - ETA: 0s - loss: 0.0148 - acc: 0.998 - ETA: 0s - loss: 0.0178 - acc: 0.997 - ETA: 0s - loss: 0.0164 - acc: 0.997 - 0s 557us/step - loss: 0.0154 - acc: 0.9975\n",
      "Epoch 118/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0158 - acc: 0.993 - ETA: 0s - loss: 0.0134 - acc: 0.994 - ETA: 0s - loss: 0.0192 - acc: 0.994 - ETA: 0s - loss: 0.0167 - acc: 0.995 - ETA: 0s - loss: 0.0288 - acc: 0.990 - ETA: 0s - loss: 0.0270 - acc: 0.991 - ETA: 0s - loss: 0.0253 - acc: 0.992 - ETA: 0s - loss: 0.0230 - acc: 0.993 - 0s 604us/step - loss: 0.0230 - acc: 0.9938\n",
      "Epoch 119/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0179 - acc: 1.000 - ETA: 0s - loss: 0.0217 - acc: 0.992 - ETA: 0s - loss: 0.0138 - acc: 0.995 - ETA: 0s - loss: 0.0132 - acc: 0.996 - ETA: 0s - loss: 0.0140 - acc: 0.997 - ETA: 0s - loss: 0.0130 - acc: 0.997 - ETA: 0s - loss: 0.0189 - acc: 0.994 - ETA: 0s - loss: 0.0172 - acc: 0.995 - ETA: 0s - loss: 0.0151 - acc: 0.996 - 0s 619us/step - loss: 0.0150 - acc: 0.9963\n",
      "Epoch 120/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0281 - acc: 1.000 - ETA: 0s - loss: 0.0239 - acc: 1.000 - ETA: 0s - loss: 0.0224 - acc: 0.995 - ETA: 0s - loss: 0.0211 - acc: 0.993 - ETA: 0s - loss: 0.0210 - acc: 0.994 - ETA: 0s - loss: 0.0209 - acc: 0.996 - ETA: 0s - loss: 0.0187 - acc: 0.996 - ETA: 0s - loss: 0.0183 - acc: 0.996 - 0s 558us/step - loss: 0.0190 - acc: 0.9963\n",
      "Epoch 121/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0272 - acc: 1.000 - ETA: 0s - loss: 0.0123 - acc: 1.000 - ETA: 0s - loss: 0.0261 - acc: 0.994 - ETA: 0s - loss: 0.0190 - acc: 0.996 - ETA: 0s - loss: 0.0201 - acc: 0.994 - ETA: 0s - loss: 0.0173 - acc: 0.995 - ETA: 0s - loss: 0.0201 - acc: 0.994 - ETA: 0s - loss: 0.0198 - acc: 0.994 - ETA: 0s - loss: 0.0219 - acc: 0.993 - 0s 610us/step - loss: 0.0217 - acc: 0.9938\n",
      "Epoch 122/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0155 - acc: 1.000 - ETA: 0s - loss: 0.0120 - acc: 1.000 - ETA: 0s - loss: 0.0212 - acc: 0.991 - ETA: 0s - loss: 0.0191 - acc: 0.992 - ETA: 0s - loss: 0.0168 - acc: 0.994 - ETA: 0s - loss: 0.0146 - acc: 0.996 - ETA: 0s - loss: 0.0126 - acc: 0.996 - ETA: 0s - loss: 0.0120 - acc: 0.997 - 0s 573us/step - loss: 0.0122 - acc: 0.9975\n",
      "Epoch 123/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0073 - acc: 1.000 - ETA: 0s - loss: 0.0071 - acc: 1.000 - ETA: 0s - loss: 0.0122 - acc: 0.995 - ETA: 0s - loss: 0.0152 - acc: 0.994 - ETA: 0s - loss: 0.0145 - acc: 0.995 - 0s 419us/step - loss: 0.0153 - acc: 0.9963\n",
      "Epoch 124/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0083 - acc: 1.000 - ETA: 0s - loss: 0.0233 - acc: 0.987 - ETA: 0s - loss: 0.0213 - acc: 0.989 - ETA: 0s - loss: 0.0174 - acc: 0.992 - ETA: 0s - loss: 0.0166 - acc: 0.994 - ETA: 0s - loss: 0.0138 - acc: 0.995 - ETA: 0s - loss: 0.0141 - acc: 0.996 - 0s 457us/step - loss: 0.0140 - acc: 0.9963\n",
      "Epoch 125/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0126 - acc: 0.993 - ETA: 0s - loss: 0.0211 - acc: 0.993 - ETA: 0s - loss: 0.0172 - acc: 0.995 - ETA: 0s - loss: 0.0197 - acc: 0.993 - ETA: 0s - loss: 0.0168 - acc: 0.994 - 0s 422us/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 126/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0167 - acc: 1.000 - ETA: 0s - loss: 0.0117 - acc: 1.000 - ETA: 0s - loss: 0.0157 - acc: 1.000 - ETA: 0s - loss: 0.0173 - acc: 0.995 - ETA: 0s - loss: 0.0169 - acc: 0.994 - ETA: 0s - loss: 0.0154 - acc: 0.995 - ETA: 0s - loss: 0.0181 - acc: 0.995 - 0s 438us/step - loss: 0.0180 - acc: 0.9950\n",
      "Epoch 127/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0117 - acc: 1.000 - ETA: 0s - loss: 0.0165 - acc: 1.000 - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0142 - acc: 0.997 - ETA: 0s - loss: 0.0161 - acc: 0.996 - ETA: 0s - loss: 0.0138 - acc: 0.997 - ETA: 0s - loss: 0.0154 - acc: 0.996 - 0s 449us/step - loss: 0.0153 - acc: 0.9963\n",
      "Epoch 128/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 5.2237e-04 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.0000    - ETA: 0s - loss: 0.0182 - acc: 0.995 - ETA: 0s - loss: 0.0134 - acc: 0.996 - ETA: 0s - loss: 0.0143 - acc: 0.997 - ETA: 0s - loss: 0.0135 - acc: 0.998 - ETA: 0s - loss: 0.0112 - acc: 0.998 - 0s 460us/step - loss: 0.0111 - acc: 0.9988\n",
      "Epoch 129/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.000 - ETA: 0s - loss: 0.0225 - acc: 0.993 - ETA: 0s - loss: 0.0250 - acc: 0.992 - ETA: 0s - loss: 0.0189 - acc: 0.994 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0175 - acc: 0.995 - ETA: 0s - loss: 0.0194 - acc: 0.994 - 0s 468us/step - loss: 0.0206 - acc: 0.9938\n",
      "Epoch 130/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0072 - acc: 1.000 - 0s 488us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0519 - acc: 0.968 - ETA: 0s - loss: 0.0148 - acc: 0.992 - ETA: 0s - loss: 0.0230 - acc: 0.992 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0165 - acc: 0.996 - ETA: 0s - loss: 0.0143 - acc: 0.996 - ETA: 0s - loss: 0.0133 - acc: 0.997 - 0s 512us/step - loss: 0.0123 - acc: 0.9975\n",
      "Epoch 132/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0082 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0080 - acc: 1.000 - ETA: 0s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0145 - acc: 0.996 - ETA: 0s - loss: 0.0164 - acc: 0.997 - ETA: 0s - loss: 0.0151 - acc: 0.997 - 0s 543us/step - loss: 0.0164 - acc: 0.9975\n",
      "Epoch 133/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0273 - acc: 0.992 - ETA: 0s - loss: 0.0174 - acc: 0.995 - ETA: 0s - loss: 0.0201 - acc: 0.993 - ETA: 0s - loss: 0.0226 - acc: 0.991 - ETA: 0s - loss: 0.0195 - acc: 0.993 - ETA: 0s - loss: 0.0179 - acc: 0.994 - 0s 496us/step - loss: 0.0161 - acc: 0.9950\n",
      "Epoch 134/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0082 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0107 - acc: 0.996 - ETA: 0s - loss: 0.0104 - acc: 0.996 - ETA: 0s - loss: 0.0095 - acc: 0.997 - 0s 519us/step - loss: 0.0102 - acc: 0.9975\n",
      "Epoch 135/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0239 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 1.000 - ETA: 0s - loss: 0.0114 - acc: 0.996 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0098 - acc: 0.996 - ETA: 0s - loss: 0.0090 - acc: 0.997 - ETA: 0s - loss: 0.0091 - acc: 0.997 - 0s 501us/step - loss: 0.0088 - acc: 0.9975\n",
      "Epoch 136/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.000 - ETA: 0s - loss: 0.0074 - acc: 1.000 - ETA: 0s - loss: 0.0083 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 1.000 - ETA: 0s - loss: 0.0189 - acc: 0.994 - ETA: 0s - loss: 0.0167 - acc: 0.995 - ETA: 0s - loss: 0.0191 - acc: 0.994 - ETA: 0s - loss: 0.0185 - acc: 0.995 - ETA: 0s - loss: 0.0217 - acc: 0.993 - 1s 655us/step - loss: 0.0212 - acc: 0.9938\n",
      "Epoch 137/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - ETA: 0s - loss: 0.0057 - acc: 1.000 - ETA: 0s - loss: 0.0110 - acc: 0.995 - ETA: 0s - loss: 0.0090 - acc: 0.996 - ETA: 0s - loss: 0.0085 - acc: 0.997 - ETA: 0s - loss: 0.0108 - acc: 0.996 - ETA: 0s - loss: 0.0094 - acc: 0.996 - ETA: 0s - loss: 0.0112 - acc: 0.995 - 0s 542us/step - loss: 0.0103 - acc: 0.9963\n",
      "Epoch 138/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 8.6323e-04 - acc: 1.000 - ETA: 0s - loss: 0.0138 - acc: 0.9938    - ETA: 0s - loss: 0.0092 - acc: 0.996 - ETA: 0s - loss: 0.0071 - acc: 0.997 - ETA: 0s - loss: 0.0065 - acc: 0.997 - ETA: 0s - loss: 0.0084 - acc: 0.998 - ETA: 0s - loss: 0.0085 - acc: 0.998 - ETA: 0s - loss: 0.0094 - acc: 0.997 - ETA: 0s - loss: 0.0091 - acc: 0.997 - 1s 634us/step - loss: 0.0098 - acc: 0.9975\n",
      "Epoch 139/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0162 - acc: 0.992 - ETA: 0s - loss: 0.0133 - acc: 0.995 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0110 - acc: 0.997 - ETA: 0s - loss: 0.0131 - acc: 0.995 - ETA: 0s - loss: 0.0128 - acc: 0.996 - ETA: 0s - loss: 0.0144 - acc: 0.994 - ETA: 0s - loss: 0.0132 - acc: 0.994 - ETA: 0s - loss: 0.0132 - acc: 0.995 - 1s 708us/step - loss: 0.0131 - acc: 0.9950\n",
      "Epoch 140/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0203 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0106 - acc: 1.000 - ETA: 0s - loss: 0.0101 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0080 - acc: 1.000 - ETA: 0s - loss: 0.0118 - acc: 0.998 - ETA: 0s - loss: 0.0127 - acc: 0.997 - ETA: 0s - loss: 0.0134 - acc: 0.996 - 0s 619us/step - loss: 0.0134 - acc: 0.9963\n",
      "Epoch 141/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0226 - acc: 1.000 - ETA: 0s - loss: 0.0139 - acc: 1.000 - ETA: 0s - loss: 0.0207 - acc: 0.995 - ETA: 0s - loss: 0.0148 - acc: 0.996 - ETA: 0s - loss: 0.0140 - acc: 0.997 - ETA: 0s - loss: 0.0181 - acc: 0.993 - ETA: 0s - loss: 0.0201 - acc: 0.993 - ETA: 0s - loss: 0.0180 - acc: 0.994 - ETA: 0s - loss: 0.0162 - acc: 0.994 - 1s 643us/step - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 142/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0146 - acc: 1.000 - ETA: 0s - loss: 0.0185 - acc: 0.992 - ETA: 0s - loss: 0.0149 - acc: 0.995 - ETA: 0s - loss: 0.0126 - acc: 0.996 - ETA: 0s - loss: 0.0108 - acc: 0.997 - ETA: 0s - loss: 0.0117 - acc: 0.997 - ETA: 0s - loss: 0.0124 - acc: 0.998 - ETA: 0s - loss: 0.0136 - acc: 0.998 - ETA: 0s - loss: 0.0123 - acc: 0.998 - 1s 658us/step - loss: 0.0114 - acc: 0.9988\n",
      "Epoch 143/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0096 - acc: 0.996 - ETA: 0s - loss: 0.0070 - acc: 0.997 - ETA: 0s - loss: 0.0091 - acc: 0.996 - ETA: 0s - loss: 0.0115 - acc: 0.995 - 0s 408us/step - loss: 0.0152 - acc: 0.9938\n",
      "Epoch 144/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.9295e-04 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.0000    - ETA: 0s - loss: 0.0120 - acc: 0.997 - ETA: 0s - loss: 0.0111 - acc: 0.997 - ETA: 0s - loss: 0.0120 - acc: 0.998 - ETA: 0s - loss: 0.0104 - acc: 0.998 - 0s 411us/step - loss: 0.0105 - acc: 0.9988\n",
      "Epoch 145/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0601 - acc: 1.000 - ETA: 0s - loss: 0.0358 - acc: 0.993 - ETA: 0s - loss: 0.0224 - acc: 0.996 - ETA: 0s - loss: 0.0238 - acc: 0.992 - ETA: 0s - loss: 0.0201 - acc: 0.994 - ETA: 0s - loss: 0.0169 - acc: 0.995 - ETA: 0s - loss: 0.0155 - acc: 0.996 - 0s 471us/step - loss: 0.0149 - acc: 0.9963\n",
      "Epoch 146/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 5.6128e-04 - acc: 1.000 - ETA: 0s - loss: 0.0151 - acc: 0.9938    - ETA: 0s - loss: 0.0235 - acc: 0.990 - ETA: 0s - loss: 0.0188 - acc: 0.993 - ETA: 0s - loss: 0.0164 - acc: 0.995 - ETA: 0s - loss: 0.0153 - acc: 0.996 - 0s 403us/step - loss: 0.0152 - acc: 0.9963\n",
      "Epoch 147/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0090 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 0.998 - 0s 412us/step - loss: 0.0067 - acc: 0.9988\n",
      "Epoch 148/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0194 - acc: 1.000 - ETA: 0s - loss: 0.0198 - acc: 0.994 - ETA: 0s - loss: 0.0169 - acc: 0.996 - ETA: 0s - loss: 0.0157 - acc: 0.997 - ETA: 0s - loss: 0.0128 - acc: 0.998 - ETA: 0s - loss: 0.0112 - acc: 0.998 - ETA: 0s - loss: 0.0101 - acc: 0.998 - 0s 455us/step - loss: 0.0101 - acc: 0.9988\n",
      "Epoch 149/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0102 - acc: 1.000 - ETA: 0s - loss: 0.0265 - acc: 0.992 - ETA: 0s - loss: 0.0205 - acc: 0.992 - ETA: 0s - loss: 0.0234 - acc: 0.992 - ETA: 0s - loss: 0.0209 - acc: 0.994 - ETA: 0s - loss: 0.0184 - acc: 0.995 - ETA: 0s - loss: 0.0160 - acc: 0.996 - 0s 457us/step - loss: 0.0162 - acc: 0.9963\n",
      "Epoch 150/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0105 - acc: 1.000 - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0076 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.000 - ETA: 0s - loss: 0.0061 - acc: 1.000 - 0s 495us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 7.9440e-04 - acc: 1.000 - ETA: 0s - loss: 0.0099 - acc: 1.0000    - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0112 - acc: 0.996 - ETA: 0s - loss: 0.0179 - acc: 0.993 - ETA: 0s - loss: 0.0170 - acc: 0.992 - ETA: 0s - loss: 0.0146 - acc: 0.993 - ETA: 0s - loss: 0.0138 - acc: 0.994 - 0s 548us/step - loss: 0.0136 - acc: 0.9950\n",
      "Epoch 152/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 4.2957e-04 - acc: 1.000 - ETA: 0s - loss: 0.0106 - acc: 1.0000    - ETA: 0s - loss: 0.0228 - acc: 0.995 - ETA: 0s - loss: 0.0173 - acc: 0.997 - ETA: 0s - loss: 0.0236 - acc: 0.993 - ETA: 0s - loss: 0.0258 - acc: 0.991 - ETA: 0s - loss: 0.0260 - acc: 0.991 - 0s 485us/step - loss: 0.0276 - acc: 0.9913\n",
      "Epoch 153/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0061 - acc: 1.000 - ETA: 0s - loss: 0.0080 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0105 - acc: 0.998 - ETA: 0s - loss: 0.0113 - acc: 0.997 - 0s 507us/step - loss: 0.0105 - acc: 0.9975\n",
      "Epoch 154/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0100 - acc: 0.996 - ETA: 0s - loss: 0.0170 - acc: 0.992 - ETA: 0s - loss: 0.0149 - acc: 0.992 - ETA: 0s - loss: 0.0133 - acc: 0.994 - ETA: 0s - loss: 0.0132 - acc: 0.994 - 0s 486us/step - loss: 0.0133 - acc: 0.9950\n",
      "Epoch 155/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 4.6919e-04 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.0000    - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 0.997 - ETA: 0s - loss: 0.0076 - acc: 0.997 - ETA: 0s - loss: 0.0131 - acc: 0.994 - ETA: 0s - loss: 0.0134 - acc: 0.995 - 0s 486us/step - loss: 0.0125 - acc: 0.9963\n",
      "Epoch 156/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0365 - acc: 0.968 - ETA: 0s - loss: 0.0131 - acc: 0.993 - ETA: 0s - loss: 0.0169 - acc: 0.993 - ETA: 0s - loss: 0.0144 - acc: 0.994 - ETA: 0s - loss: 0.0149 - acc: 0.995 - ETA: 0s - loss: 0.0140 - acc: 0.996 - ETA: 0s - loss: 0.0122 - acc: 0.997 - ETA: 0s - loss: 0.0144 - acc: 0.995 - ETA: 0s - loss: 0.0133 - acc: 0.996 - 0s 610us/step - loss: 0.0132 - acc: 0.9963\n",
      "Epoch 157/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0112 - acc: 1.000 - ETA: 0s - loss: 0.0178 - acc: 0.993 - ETA: 0s - loss: 0.0228 - acc: 0.992 - ETA: 0s - loss: 0.0190 - acc: 0.994 - ETA: 0s - loss: 0.0185 - acc: 0.995 - ETA: 0s - loss: 0.0162 - acc: 0.996 - ETA: 0s - loss: 0.0148 - acc: 0.997 - ETA: 0s - loss: 0.0128 - acc: 0.997 - 0s 535us/step - loss: 0.0127 - acc: 0.9975\n",
      "Epoch 158/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.000 - ETA: 0s - loss: 0.0089 - acc: 1.000 - ETA: 0s - loss: 0.0061 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0059 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 545us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0264 - acc: 1.000 - ETA: 0s - loss: 0.0203 - acc: 1.000 - ETA: 0s - loss: 0.0115 - acc: 1.000 - ETA: 0s - loss: 0.0150 - acc: 0.996 - ETA: 0s - loss: 0.0124 - acc: 0.997 - ETA: 0s - loss: 0.0141 - acc: 0.995 - ETA: 0s - loss: 0.0193 - acc: 0.994 - ETA: 0s - loss: 0.0184 - acc: 0.995 - ETA: 0s - loss: 0.0176 - acc: 0.994 - 1s 633us/step - loss: 0.0167 - acc: 0.9950\n",
      "Epoch 160/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0122 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0081 - acc: 0.996 - ETA: 0s - loss: 0.0065 - acc: 0.997 - ETA: 0s - loss: 0.0062 - acc: 0.997 - ETA: 0s - loss: 0.0085 - acc: 0.998 - ETA: 0s - loss: 0.0081 - acc: 0.998 - ETA: 0s - loss: 0.0090 - acc: 0.998 - ETA: 0s - loss: 0.0135 - acc: 0.997 - 1s 715us/step - loss: 0.0129 - acc: 0.9975\n",
      "Epoch 161/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0062 - acc: 1.000 - ETA: 0s - loss: 0.0057 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0117 - acc: 0.998 - ETA: 0s - loss: 0.0108 - acc: 0.998 - 1s 757us/step - loss: 0.0107 - acc: 0.9988\n",
      "Epoch 162/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.0706e-04 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.0000    - ETA: 0s - loss: 0.0023 - acc: 1.000 - ETA: 0s - loss: 0.0111 - acc: 0.996 - ETA: 0s - loss: 0.0084 - acc: 0.997 - ETA: 0s - loss: 0.0133 - acc: 0.993 - ETA: 0s - loss: 0.0118 - acc: 0.994 - ETA: 0s - loss: 0.0104 - acc: 0.995 - ETA: 0s - loss: 0.0094 - acc: 0.995 - ETA: 0s - loss: 0.0090 - acc: 0.996 - 1s 679us/step - loss: 0.0089 - acc: 0.9963\n",
      "Epoch 163/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0485 - acc: 0.968 - ETA: 0s - loss: 0.0165 - acc: 0.989 - ETA: 0s - loss: 0.0228 - acc: 0.993 - ETA: 0s - loss: 0.0149 - acc: 0.996 - ETA: 0s - loss: 0.0126 - acc: 0.997 - ETA: 0s - loss: 0.0125 - acc: 0.997 - ETA: 0s - loss: 0.0108 - acc: 0.998 - ETA: 0s - loss: 0.0095 - acc: 0.998 - 0s 576us/step - loss: 0.0093 - acc: 0.9988\n",
      "Epoch 164/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0102 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0176 - acc: 0.994 - ETA: 0s - loss: 0.0147 - acc: 0.996 - ETA: 0s - loss: 0.0142 - acc: 0.995 - 0s 336us/step - loss: 0.0127 - acc: 0.9963\n",
      "Epoch 165/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 6.5586e-04 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.0000    - ETA: 0s - loss: 0.0155 - acc: 0.994 - ETA: 0s - loss: 0.0143 - acc: 0.996 - ETA: 0s - loss: 0.0176 - acc: 0.995 - 0s 349us/step - loss: 0.0163 - acc: 0.9963\n",
      "Epoch 166/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 1.000 - ETA: 0s - loss: 0.0087 - acc: 1.000 - ETA: 0s - loss: 0.0077 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 0.998 - 0s 342us/step - loss: 0.0078 - acc: 0.9988\n",
      "Epoch 167/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0159 - acc: 0.989 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0103 - acc: 0.997 - ETA: 0s - loss: 0.0113 - acc: 0.998 - ETA: 0s - loss: 0.0092 - acc: 0.998 - 0s 404us/step - loss: 0.0093 - acc: 0.9988\n",
      "Epoch 168/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0454 - acc: 1.000 - ETA: 0s - loss: 0.0209 - acc: 1.000 - ETA: 0s - loss: 0.0179 - acc: 1.000 - ETA: 0s - loss: 0.0125 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 1.000 - 0s 380us/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 7.6537e-04 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.0000    - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0109 - acc: 0.996 - ETA: 0s - loss: 0.0099 - acc: 0.997 - 0s 351us/step - loss: 0.0112 - acc: 0.9963\n",
      "Epoch 170/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0073 - acc: 1.000 - ETA: 0s - loss: 0.0111 - acc: 1.000 - ETA: 0s - loss: 0.0079 - acc: 1.000 - ETA: 0s - loss: 0.0097 - acc: 0.998 - ETA: 0s - loss: 0.0094 - acc: 0.998 - 0s 320us/step - loss: 0.0096 - acc: 0.9988\n",
      "Epoch 171/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - ETA: 0s - loss: 0.0104 - acc: 0.997 - ETA: 0s - loss: 0.0086 - acc: 0.998 - 0s 347us/step - loss: 0.0087 - acc: 0.9988\n",
      "Epoch 172/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0114 - acc: 0.995 - ETA: 0s - loss: 0.0097 - acc: 0.997 - ETA: 0s - loss: 0.0141 - acc: 0.996 - ETA: 0s - loss: 0.0123 - acc: 0.997 - 0s 323us/step - loss: 0.0115 - acc: 0.9975\n",
      "Epoch 173/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.000 - ETA: 0s - loss: 0.0155 - acc: 0.993 - ETA: 0s - loss: 0.0178 - acc: 0.990 - ETA: 0s - loss: 0.0187 - acc: 0.991 - ETA: 0s - loss: 0.0159 - acc: 0.993 - ETA: 0s - loss: 0.0197 - acc: 0.993 - 0s 383us/step - loss: 0.0189 - acc: 0.9938\n",
      "Epoch 174/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0166 - acc: 0.991 - ETA: 0s - loss: 0.0117 - acc: 0.994 - ETA: 0s - loss: 0.0112 - acc: 0.994 - ETA: 0s - loss: 0.0094 - acc: 0.995 - ETA: 0s - loss: 0.0094 - acc: 0.996 - 0s 373us/step - loss: 0.0093 - acc: 0.9963\n",
      "Epoch 175/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0146 - acc: 1.000 - ETA: 0s - loss: 0.0155 - acc: 0.996 - ETA: 0s - loss: 0.0123 - acc: 0.997 - ETA: 0s - loss: 0.0100 - acc: 0.998 - ETA: 0s - loss: 0.0081 - acc: 0.998 - 0s 434us/step - loss: 0.0084 - acc: 0.9988\n",
      "Epoch 176/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0037 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0051 - acc: 1.000 - 0s 336us/step - loss: 0.0096 - acc: 0.9988\n",
      "Epoch 177/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0259 - acc: 0.993 - ETA: 0s - loss: 0.0158 - acc: 0.996 - ETA: 0s - loss: 0.0123 - acc: 0.998 - ETA: 0s - loss: 0.0125 - acc: 0.996 - ETA: 0s - loss: 0.0115 - acc: 0.997 - 0s 376us/step - loss: 0.0114 - acc: 0.9975\n",
      "Epoch 178/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 7.4035e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0050 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0047 - acc: 1.000 - 0s 387us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0206 - acc: 0.993 - ETA: 0s - loss: 0.0172 - acc: 0.993 - ETA: 0s - loss: 0.0134 - acc: 0.995 - ETA: 0s - loss: 0.0131 - acc: 0.996 - ETA: 0s - loss: 0.0168 - acc: 0.995 - ETA: 0s - loss: 0.0171 - acc: 0.995 - 0s 463us/step - loss: 0.0170 - acc: 0.9950\n",
      "Epoch 180/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0238 - acc: 1.000 - ETA: 0s - loss: 0.0117 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0090 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 1.000 - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 0.998 - 0s 525us/step - loss: 0.0097 - acc: 0.9988\n",
      "Epoch 181/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0032 - acc: 1.000 - ETA: 0s - loss: 0.0053 - acc: 1.000 - ETA: 0s - loss: 0.0108 - acc: 0.997 - ETA: 0s - loss: 0.0100 - acc: 0.997 - ETA: 0s - loss: 0.0100 - acc: 0.998 - ETA: 0s - loss: 0.0090 - acc: 0.998 - 0s 526us/step - loss: 0.0086 - acc: 0.9988\n",
      "Epoch 182/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.000 - ETA: 0s - loss: 0.0134 - acc: 0.993 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0102 - acc: 0.997 - ETA: 0s - loss: 0.0094 - acc: 0.998 - ETA: 0s - loss: 0.0080 - acc: 0.998 - ETA: 0s - loss: 0.0090 - acc: 0.997 - 0s 516us/step - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 183/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0049 - acc: 1.000 - ETA: 0s - loss: 0.0025 - acc: 1.000 - ETA: 0s - loss: 0.0202 - acc: 0.994 - ETA: 0s - loss: 0.0253 - acc: 0.993 - ETA: 0s - loss: 0.0199 - acc: 0.994 - ETA: 0s - loss: 0.0177 - acc: 0.995 - ETA: 0s - loss: 0.0163 - acc: 0.996 - ETA: 0s - loss: 0.0148 - acc: 0.996 - ETA: 0s - loss: 0.0129 - acc: 0.997 - 1s 639us/step - loss: 0.0124 - acc: 0.9975\n",
      "Epoch 184/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.6994e-04 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.0000    - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0064 - acc: 1.000 - ETA: 0s - loss: 0.0100 - acc: 1.000 - ETA: 0s - loss: 0.0092 - acc: 1.000 - ETA: 0s - loss: 0.0132 - acc: 0.998 - ETA: 0s - loss: 0.0113 - acc: 0.998 - 0s 566us/step - loss: 0.0113 - acc: 0.9988\n",
      "Epoch 185/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 2.5026e-04 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.0000    - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 0.998 - ETA: 0s - loss: 0.0061 - acc: 0.998 - ETA: 0s - loss: 0.0055 - acc: 0.998 - 0s 551us/step - loss: 0.0051 - acc: 0.9988\n",
      "Epoch 186/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0123 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.000 - ETA: 0s - loss: 0.0031 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 0.997 - ETA: 0s - loss: 0.0079 - acc: 0.998 - ETA: 0s - loss: 0.0077 - acc: 0.998 - ETA: 0s - loss: 0.0076 - acc: 0.998 - 1s 630us/step - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 187/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0273 - acc: 1.000 - ETA: 0s - loss: 0.0199 - acc: 0.993 - ETA: 0s - loss: 0.0150 - acc: 0.996 - ETA: 0s - loss: 0.0112 - acc: 0.997 - ETA: 0s - loss: 0.0096 - acc: 0.997 - ETA: 0s - loss: 0.0100 - acc: 0.997 - ETA: 0s - loss: 0.0094 - acc: 0.997 - 1s 636us/step - loss: 0.0091 - acc: 0.9975\n",
      "Epoch 188/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0229 - acc: 0.991 - ETA: 0s - loss: 0.0173 - acc: 0.995 - ETA: 0s - loss: 0.0208 - acc: 0.992 - ETA: 0s - loss: 0.0180 - acc: 0.994 - ETA: 0s - loss: 0.0172 - acc: 0.994 - 0s 535us/step - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 189/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0257 - acc: 0.968 - ETA: 0s - loss: 0.0064 - acc: 0.995 - ETA: 0s - loss: 0.0088 - acc: 0.994 - ETA: 0s - loss: 0.0104 - acc: 0.996 - ETA: 0s - loss: 0.0117 - acc: 0.995 - 0s 331us/step - loss: 0.0116 - acc: 0.9963\n",
      "Epoch 190/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0059 - acc: 1.000 - ETA: 0s - loss: 0.0078 - acc: 0.997 - ETA: 0s - loss: 0.0085 - acc: 0.996 - ETA: 0s - loss: 0.0090 - acc: 0.997 - 0s 392us/step - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 191/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0155 - acc: 0.994 - ETA: 0s - loss: 0.0125 - acc: 0.997 - ETA: 0s - loss: 0.0107 - acc: 0.997 - ETA: 0s - loss: 0.0085 - acc: 0.998 - ETA: 0s - loss: 0.0104 - acc: 0.995 - 0s 396us/step - loss: 0.0110 - acc: 0.9963\n",
      "Epoch 192/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0198 - acc: 1.000 - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0134 - acc: 0.996 - ETA: 0s - loss: 0.0102 - acc: 0.997 - ETA: 0s - loss: 0.0250 - acc: 0.995 - ETA: 0s - loss: 0.0210 - acc: 0.996 - 0s 373us/step - loss: 0.0201 - acc: 0.9963\n",
      "Epoch 193/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.000 - ETA: 0s - loss: 0.0122 - acc: 0.993 - ETA: 0s - loss: 0.0095 - acc: 0.996 - ETA: 0s - loss: 0.0066 - acc: 0.997 - ETA: 0s - loss: 0.0136 - acc: 0.996 - ETA: 0s - loss: 0.0130 - acc: 0.996 - 0s 397us/step - loss: 0.0126 - acc: 0.9963\n",
      "Epoch 194/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0161 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0048 - acc: 1.000 - ETA: 0s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 0.998 - 0s 326us/step - loss: 0.0087 - acc: 0.9988\n",
      "Epoch 195/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0040 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 382us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 6.6088e-04 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.0000    - ETA: 0s - loss: 0.0109 - acc: 1.000 - ETA: 0s - loss: 0.0076 - acc: 1.000 - ETA: 0s - loss: 0.0063 - acc: 1.000 - ETA: 0s - loss: 0.0058 - acc: 1.000 - ETA: 0s - loss: 0.0102 - acc: 0.998 - ETA: 0s - loss: 0.0084 - acc: 0.998 - 0s 556us/step - loss: 0.0084 - acc: 0.9988\n",
      "Epoch 197/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0022 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 411us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.000 - ETA: 0s - loss: 0.0255 - acc: 0.995 - ETA: 0s - loss: 0.0230 - acc: 0.996 - ETA: 0s - loss: 0.0145 - acc: 0.997 - ETA: 0s - loss: 0.0122 - acc: 0.998 - ETA: 0s - loss: 0.0116 - acc: 0.998 - ETA: 0s - loss: 0.0096 - acc: 0.998 - 0s 510us/step - loss: 0.0089 - acc: 0.9988\n",
      "Epoch 199/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 0.0058 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.000 - ETA: 0s - loss: 0.0052 - acc: 0.998 - 1s 800us/step - loss: 0.0048 - acc: 0.9988\n",
      "Epoch 200/200\n",
      "806/806 [==============================] - ETA: 0s - loss: 3.9446e-04 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.0000    - ETA: 0s - loss: 0.0028 - acc: 1.000 - ETA: 0s - loss: 0.0050 - acc: 1.000 - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0040 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 0.998 - ETA: 0s - loss: 0.0054 - acc: 0.998 - 0s 618us/step - loss: 0.0053 - acc: 0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Persisted model to 'C:\\mie1513\\assignment-cai-sfalaki\\assignment\\models\\dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies import KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.policies.keras_policy import KerasPolicy\n",
    "from rasa_core.policies.fallback import FallbackPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "#Adding Fallback action \n",
    "fallback = FallbackPolicy(fallback_action_name=\"action_default_fallback\",core_threshold= 0.2, nlu_threshold=0.2)\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(),fallback])\n",
    "\n",
    "# loading our training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split=0.0,\n",
    "    epochs=200\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction Demo\n",
    "### The sample stories are as follows:\n",
    "<img src=\"graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "\n",
    "### **In order to develop the chatbot, a server which listens to the user's requests is set up and the two trained models are deployed to make conversation with user.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test 1:\n",
    " The main goal in this section is asking chatbot to give some general information about the movie. The chatbot is designed to return general about Director name, first leading actor and IMDB score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hello there\n",
      "Hey!!\n",
      "give me information about the circle\n",
      "General Information aboutthe circle movie:\n",
      " Director is Jafar Panahi\n",
      " Leading Actor\u0007ctress is Fereshteh Sadre Orafaiy \n",
      " IMDB score is 7.5  \n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    #pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2\n",
    "In this part, the main goal of the stories is checking the content rating of movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "what is the content rating of titanic?\n",
      "Content rating of titanic movie is PG-13 \n",
      "thanks\n",
      "No Problem\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    #pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "Hey!!\n",
      "Is this movie safe for children to watch?\n",
      "What is the name of the movie?\n",
      "the matrix\n",
      "Content rating of the matrix movie is R \n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    #pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3\n",
    "The idea in this section is getting the name of 5 profitable movies by having the user's preferences. \n",
    "First, the profit feature is calculated using the \"gross\" and \"budget\" features.\n",
    "Also, some of information that chatbot used to return the 5 profitable movies are \"genre\",\"year\",\"imdb_score\" and \"color\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "Recommend some romance movies that are produced after 2010\n",
      "please enter the minimum acceptable IMDB score\n",
      "7.3\n",
      "Top 5 profitable movies with your desired criteria are :\n",
      "deadpool             305024263.0\n",
      "the king's speech             123795342.0\n",
      "the fault in our stars             112868837.0\n",
      "silver linings playbook             111088910.0\n",
      "les misérables             87775460.0\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    #pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "suggest some popular black and white movie\n",
      "which genre do you like?\n",
      "action\n",
      "Top 5 profitable movies with your desired criteria are :\n",
      "pearl harbor             58539855.0\n",
      "kill bill: vol. 1             40098138.0\n",
      "kill bill: vol. 2             36207920.0\n",
      "space cowboys             25454043.0\n",
      "die another day             18201106.0\n",
      "thank you\n",
      "No Problem\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    #pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "Hey!!\n",
      "list the movies with horror genre\n",
      "What is the year the movie is produced after\n",
      "1990\n",
      "please enter the minimum acceptable IMDB score\n",
      "5.6\n",
      "Top 5 profitable movies with your desired criteria are :\n",
      "the blair witch project             140470114.0\n",
      "the conjuring             117387272.0\n",
      "the silence of the lambs             111727000.0\n",
      "paranormal activity             107902283.0\n",
      "i am legend             106386216.0\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "interpreter = NaturalLanguageInterpreter.create('models/nlu/default/current/')\n",
    "endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "agent = Agent.load('models/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "tracker = agent.tracker_store.get_or_create_tracker(\"sender_id\") \n",
    "# get current tracker state\n",
    "tracker.current_state()\n",
    "\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    #pprint(interpreter.parse(a))\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The end 😁**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
